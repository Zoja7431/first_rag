# ========================================
# Конфигурация RAG системы психолога
# ========================================

# Пути к данным
data:
  pdf_path: "data/psichology_books/"
  books:
    - "Allana-Piza-YAzyk-telodvizhenij"
    - "Eric-Berne-games-that-people-play"
    - "Goleman-D.-Emotional-Intelligence.-Why-it-may-be-more-important-than-IQ"
    - "Gurina-Koshenova-Rabota-psikhologa-s_detskoi"
    - "Psihology-Aykido"
    - "Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauchitsya-ubezhdat-y-dobivatsya-uspeha"

# Обработка текста
text_processing:
  # Параметры Chonkie chunker
  chunk_size: 512  # Размер чанка в токенах
  overlap_size: 50  # Перекрытие между чанками
  
  # Параметры spaCy
  spacy_model: "ru_core_news_sm"

# Эмбеддинги
embeddings:
  # HuggingFace модель для эмбеддингов
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  # Размер эмбеддинга (зависит от модели)
  embedding_dim: 384
  # Параметры для инициализации
  device: "cuda" 
  model_kwargs:
    trust_remote_code: true

# Qdrant векторная база
qdrant:
  # URL Qdrant (берется из .env: QDRANT_URL)
  url: "${QDRANT_URL}"
  # API ключ для Qdrant Cloud (берется из .env: QDRANT_API_KEY)
  api_key: "${QDRANT_API_KEY}"
  # Имя коллекции
  collection_name: "psychology_rag"
  # Размер вектора (должен совпадать с embedding_dim)
  vector_size: 384
  # Расстояние для поиска сходства
  distance: "cosine"
  # Параметры поиска
  search_limit: 4  # Количество результатов поиска

# LLM (Language Model)
llm:
  type: "groq"
  groq:
    # API ключ для Groq (берется из .env: GROQ_API_KEY)
    api_key: "${GROQ_API_KEY}"
    models:
      # - "llama-3.1-8b-instant"       # Быстрая
      - "llama-3.3-70b-versatile"    # Лучшая
      # - "qwen/qwen3-32b"             # Качество
      # - "openai/gpt-oss-120b"        # Гигант
      # - "groq/compound-mini"         # Специальная
    temperature: 0.1
    max_tokens: 1024

# Промпт для RAG
prompt:
  system_role: "Вы опытный психолог с знаниями из лучших книг по психологии. Отвечайте на вопросы пользователя, используя предоставленный контекст. Будьте эмпатичны, конструктивны и профессиональны."
  
  retrieval_template: |
    Контекст из книг:
    {context}
    
    Вопрос: {question}
    
    Ответ:

# LangGraph параметры
graph:
  checkpointer: "memory"  # "memory" или "postgres" для продакшена
  max_iterations: 10
  timeout: 30

# Логирование
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Docker параметры (для docker-compose)
docker:
  qdrant_port: 6333
  qdrant_volume: "./qdrant_storage"
  app_port: 8000
