"""
—Ç–µ—Å—Ç—ã/test_chunking_integration.py (–û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–û –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô)

–§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢ - –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞:
‚úÖ config.py (overlap_size –≤ config, –Ω–µ –≤ RecursiveChunker)
‚úÖ data_loader.py (chonkie RecursiveChunker —Å –¢–û–õ–¨–ö–û chunk_size)
‚úÖ embeddings.py (HF embeddings)
‚úÖ vector_store.py (Qdrant cloud)

–ó–∞–ø—É—Å–∫: pytest src/tests/test_chunking_integration.py -v -s

‚ö†Ô∏è –í–ê–ñ–ù–û: RecursiveChunker –ù–ï –ø—Ä–∏–Ω–∏–º–∞–µ—Ç overlap –ø–∞—Ä–∞–º–µ—Ç—Ä!
Overlap –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ OverlapRefinery –ø–æ—Å–ª–µ chunking.
"""

import sys
from pathlib import Path

# sys.path fix - –≤–∞–∂–Ω–æ –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤ –∏–∑ src
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

import pytest
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è pytest
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# –¢–ï–°–¢–´
# ============================================================================

class TestConfig:
    """–¢–µ—Å—Ç—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    
    def test_config_loading(self):
        """‚úÖ –¢–µ—Å—Ç 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞"""
        from src.config import get_config
        
        config = get_config()
        assert config is not None
        logger.info("‚úÖ Config loaded")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        assert hasattr(config, 'data'), "Missing 'data' section"
        assert hasattr(config, 'text_processing'), "Missing 'text_processing' section"
        assert hasattr(config, 'embeddings'), "Missing 'embeddings' section"
        assert hasattr(config, 'qdrant'), "Missing 'qdrant' section"
        logger.info("‚úÖ All config sections present")
    
    def test_text_processing_config(self):
        """‚úÖ –¢–µ—Å—Ç 2: Text Processing –∫–æ–Ω—Ñ–∏–≥"""
        from src.config import get_config
        
        config = get_config()
        tp = config.text_processing
        
        # ‚úÖ –í–ê–ñ–ù–û: overlap_size —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ config, –Ω–æ –ù–ï –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –≤ RecursiveChunker!
        assert hasattr(tp, 'chunk_size'), "Missing chunk_size in text_processing"
        assert hasattr(tp, 'overlap_size'), "Missing overlap_size (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è OverlapRefinery, –Ω–µ –¥–ª—è RecursiveChunker)"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
        assert isinstance(tp.chunk_size, int), f"chunk_size should be int, got {type(tp.chunk_size)}"
        assert isinstance(tp.overlap_size, int), f"overlap_size should be int, got {type(tp.overlap_size)}"
        
        logger.info(f"‚úÖ Chunking config: chunk_size={tp.chunk_size}, overlap_size={tp.overlap_size}")
    
    def test_qdrant_config(self):
        """‚úÖ –¢–µ—Å—Ç 3: Qdrant –∫–æ–Ω—Ñ–∏–≥"""
        from src.config import get_config
        
        config = get_config()
        qdrant = config.qdrant
        
        assert qdrant.url, "Missing qdrant.url"
        assert qdrant.api_key, "Missing qdrant.api_key"
        assert qdrant.collection_name, "Missing qdrant.collection_name"
        assert hasattr(qdrant, 'full_url'), "Missing full_url property"
        
        logger.info(f"‚úÖ Qdrant configured: {qdrant.collection_name}")


class TestDataLoader:
    """–¢–µ—Å—Ç—ã –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏—è PDF"""
    
    def test_clean_text(self):
        """‚úÖ –¢–µ—Å—Ç 4: –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        from src.data_loader import PDFChunker
        
        try:
            chunker = PDFChunker()
            
            # –¢–µ—Å—Ç 1: –¥–µ—Ñ–∏—Å—ã
            test1_input = "–ø–∞—Ü–∏–µ–Ω—Ç- –≤–æ–ª- –Ω—É–µ–º—ã–º"
            result = chunker.clean_text(test1_input)
            print(f"\nüìù Test 1 - Input: '{test1_input}'")
            print(f"üìù Test 1 - Output: '{result}'")
            assert "–ø–∞—Ü–∏–µ–Ω—Ç" in result, f"Expected '–ø–∞—Ü–∏–µ–Ω—Ç' in '{result}'"
            
            # –¢–µ—Å—Ç 2: –ø—Ä–æ–±–µ–ª—ã/–Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
            test2_input = "–¢–µ–∫—Å—Ç\n  —Å\n–ø—Ä–æ–±–µ–ª–∞–º–∏\xa0 "
            result = chunker.clean_text(test2_input)
            print(f"üìù Test 2 - Input: {repr(test2_input)}")
            print(f"üìù Test 2 - Output: '{result}'")
            assert result == "–¢–µ–∫—Å—Ç —Å –ø—Ä–æ–±–µ–ª–∞–º–∏", f"Expected '–¢–µ–∫—Å—Ç —Å –ø—Ä–æ–±–µ–ª–∞–º–∏', got '{result}'"
            
            logger.info("‚úÖ Text cleaning works correctly")
            
        except TypeError as e:
            if "chunk_overlap" in str(e) or "overlap_size" in str(e):
                pytest.fail(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: RecursiveChunker –ù–ï –ø—Ä–∏–Ω–∏–º–∞–µ—Ç overlap –ø–∞—Ä–∞–º–µ—Ç—Ä!\n"
                          f"RecursiveChunker(chunk_size=...) - –¢–û–õ–¨–ö–û chunk_size!\n"
                          f"Overlap –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ OverlapRefinery –ø–æ—Å–ª–µ chunking.\n{e}")
            raise
    
    def test_pdf_chunker_init(self):
        """‚úÖ –¢–µ—Å—Ç 5: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è PDFChunker"""
        from src.data_loader import PDFChunker
        
        try:
            chunker = PDFChunker()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —á–∞–Ω–∫–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
            assert hasattr(chunker, 'chunker'), "PDFChunker missing 'chunker' attribute"
            assert hasattr(chunker, 'overlap_size'), "PDFChunker missing 'overlap_size' attribute"
            
            logger.info(f"‚úÖ PDFChunker initialized (RecursiveChunker chunk_size={chunker.chunker.chunk_size}, overlap_size={chunker.overlap_size})")
            
        except TypeError as e:
            if "chunk_overlap" in str(e) or "overlap_size" in str(e):
                pytest.fail(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: RecursiveChunker –ø–∞—Ä–∞–º–µ—Ç—Ä.\n"
                          f"–ü—Ä–∞–≤–∏–ª—å–Ω–æ: RecursiveChunker(chunk_size=512) - –ë–ï–ó overlap!\n"
                          f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ: RecursiveChunker(chunk_size=512, chunk_overlap=50)\n{e}")
            raise
        except Exception as e:
            pytest.skip(f"‚ö†Ô∏è PDFChunker init skipped: {e}")
    
    def test_pdf_loader_single(self):
        """‚úÖ –¢–µ—Å—Ç 6: –ó–∞–≥—Ä—É–∑–∫–∞ –æ–¥–Ω–æ–≥–æ PDF"""
        from src.config import get_config
        from src.data_loader import get_pdf_chunker
        
        config = get_config()
        pdf_dir = Path(config.data.pdf_path)
        
        if not pdf_dir.exists():
            pytest.skip(f"‚ö†Ô∏è PDF dir not found: {pdf_dir}")
        
        pdf_files = list(pdf_dir.glob("*.pdf"))
        if not pdf_files:
            pytest.skip(f"‚ö†Ô∏è No PDF files in {pdf_dir}")
        
        test_pdf = str(pdf_files[0])
        print(f"\nüìÑ Testing PDF: {Path(test_pdf).name}")
        
        try:
            chunker = get_pdf_chunker()
            chunks = chunker.load_and_chunk_pdf(test_pdf)
            
            assert len(chunks) > 0, f"Expected >0 chunks, got {len(chunks)}"
            
            first_chunk = chunks[0]
            assert first_chunk.page_content, "First chunk has no content"
            assert "book" in first_chunk.metadata, "Missing 'book' in metadata"
            assert "chunk_id" in first_chunk.metadata, "Missing 'chunk_id' in metadata"
            
            print(f"üìä Total chunks: {len(chunks)}")
            print(f"1Ô∏è‚É£ First chunk length: {len(first_chunk.page_content)} chars")
            print(f"üìç Metadata keys: {list(first_chunk.metadata.keys())}")
            
            logger.info(f"‚úÖ Loaded {len(chunks)} chunks from {Path(test_pdf).name}")
            
        except Exception as e:
            pytest.skip(f"‚ö†Ô∏è PDF loading skipped: {e}")
    
    def test_pdf_loader_multiple(self):
        """‚úÖ –¢–µ—Å—Ç 7: –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö PDF"""
        from src.config import get_config
        from src.data_loader import get_pdf_chunker
        
        config = get_config()
        pdf_dir = Path(config.data.pdf_path)
        
        if not pdf_dir.exists():
            pytest.skip(f"‚ö†Ô∏è PDF dir not found: {pdf_dir}")
        
        pdf_files = list(pdf_dir.glob("*.pdf"))[:2]
        if len(pdf_files) < 1:
            pytest.skip(f"‚ö†Ô∏è Not enough PDFs")
        
        pdf_paths = [str(f) for f in pdf_files]
        print(f"\nüìö Testing {len(pdf_paths)} PDFs")
        
        try:
            chunker = get_pdf_chunker()
            all_chunks = chunker.load_multiple(pdf_paths)
            
            assert len(all_chunks) > 0, "Expected >0 chunks from multiple PDFs"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
            books = set(c.metadata.get('book', 'unknown') for c in all_chunks)
            print(f"üìä Total chunks: {len(all_chunks)}")
            print(f"üìö Unique books: {len(books)} - {books}")
            
            logger.info(f"‚úÖ Loaded {len(all_chunks)} chunks from {len(books)} books")
            
        except Exception as e:
            pytest.skip(f"‚ö†Ô∏è Multiple PDF loading skipped: {e}")


class TestEmbeddings:
    """–¢–µ—Å—Ç—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
    
    def test_embeddings_manager_init(self):
        """‚úÖ –¢–µ—Å—Ç 8: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è EmbeddingsManager"""
        try:
            from src.embeddings import get_embeddings_manager
            
            manager = get_embeddings_manager()
            assert manager is not None, "EmbeddingsManager is None"
            
            logger.info("‚úÖ EmbeddingsManager initialized")
            
        except ImportError as e:
            if "sentence_transformers" in str(e):
                pytest.skip(f"‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢–°–Ø –£–°–¢–ê–ù–û–í–ò–¢–¨: pip install sentence-transformers\n{e}")
            raise
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Embeddings init failed: {e}")
            pytest.skip(f"Embeddings not available (expected on first run): {e}")
    
    def test_embeddings_singleton(self):
        """‚úÖ –¢–µ—Å—Ç 9: Singleton –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è embeddings"""
        try:
            from src.embeddings import get_embeddings_manager
            
            manager1 = get_embeddings_manager()
            manager2 = get_embeddings_manager()
            
            assert manager1 is manager2, "Singleton pattern broken for embeddings"
            
            logger.info("‚úÖ Embeddings singleton pattern works")
            
        except ImportError as e:
            if "sentence_transformers" in str(e):
                pytest.skip(f"‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢–°–Ø: pip install sentence-transformers")
            raise
        except Exception as e:
            pytest.skip(f"Embeddings singleton test skipped: {e}")


class TestVectorStore:
    """–¢–µ—Å—Ç—ã vector store"""
    
    def test_vector_store_config(self):
        """‚úÖ –¢–µ—Å—Ç 10: Vector Store –∫–æ–Ω—Ñ–∏–≥"""
        from src.config import get_config
        
        config = get_config()
        vs = config.qdrant
        
        assert vs.url, "Missing qdrant.url"
        assert vs.api_key, "Missing qdrant.api_key"
        assert vs.collection_name, "Missing qdrant.collection_name"
        assert vs.vector_size, "Missing qdrant.vector_size"
        
        logger.info(f"‚úÖ Vector store config OK: {vs.collection_name}")
    
    def test_vector_store_manager_init(self):
        """‚úÖ –¢–µ—Å—Ç 11: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è VectorStoreManager"""
        try:
            from src.vector_store import get_vector_store_manager
            
            manager = get_vector_store_manager()
            assert manager is not None, "VectorStoreManager is None"
            
            logger.info("‚úÖ VectorStoreManager initialized")
            
        except ImportError as e:
            if "sentence_transformers" in str(e):
                pytest.skip(f"‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢–°–Ø: pip install sentence-transformers")
            raise
        except Exception as e:
            if any(x in str(e).lower() for x in ["qdrant", "connection", "timeout"]):
                logger.warning(f"‚ö†Ô∏è Qdrant connection issue (expected if offline): {e}")
                pytest.skip(f"Qdrant not available: {e}")
            raise
    
    def test_vector_store_singleton(self):
        """‚úÖ –¢–µ—Å—Ç 12: Singleton –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è vector store"""
        try:
            from src.vector_store import get_vector_store_manager
            
            manager1 = get_vector_store_manager()
            manager2 = get_vector_store_manager()
            
            assert manager1 is manager2, "Singleton pattern broken for vector store"
            
            logger.info("‚úÖ Vector store singleton pattern works")
            
        except ImportError as e:
            if "sentence_transformers" in str(e):
                pytest.skip(f"‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢–°–Ø: pip install sentence-transformers")
            raise
        except Exception as e:
            pytest.skip(f"Vector store singleton test skipped: {e}")


class TestFullPipeline:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    
    def test_chunk_document_flow(self):
        """‚úÖ –¢–µ—Å—Ç 13: –ü–æ–ª–Ω—ã–π –ø–æ—Ç–æ–∫ chunk ‚Üí Document"""
        from src.config import get_config
        from src.data_loader import get_pdf_chunker
        
        config = get_config()
        pdf_dir = Path(config.data.pdf_path)
        
        if not pdf_dir.exists():
            pytest.skip(f"‚ö†Ô∏è PDF dir not found: {pdf_dir}")
        
        pdf_files = list(pdf_dir.glob("*.pdf"))
        if not pdf_files:
            pytest.skip("‚ö†Ô∏è No PDFs")
        
        try:
            chunker = get_pdf_chunker()
            chunks = chunker.load_and_chunk_pdf(str(pdf_files[0]))
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É Document
            for i, chunk in enumerate(chunks[:3]):
                assert hasattr(chunk, 'page_content'), f"Chunk {i} missing page_content"
                assert hasattr(chunk, 'metadata'), f"Chunk {i} missing metadata"
                assert isinstance(chunk.page_content, str), f"Chunk {i} page_content is not string"
                assert isinstance(chunk.metadata, dict), f"Chunk {i} metadata is not dict"
                assert len(chunk.page_content) > 0, f"Chunk {i} has empty content"
                
                if i == 0:
                    print(f"\nüìÑ Document structure:")
                    print(f"   Content length: {len(chunk.page_content)} chars")
                    print(f"   Content preview: {chunk.page_content[:100]}...")
                    print(f"   Metadata: {chunk.metadata}")
            
            logger.info(f"‚úÖ All {len(chunks)} chunks are valid LangChain Documents")
            
        except Exception as e:
            pytest.skip(f"Pipeline test skipped: {e}")
    
    def test_metadata_integrity(self):
        """‚úÖ –¢–µ—Å—Ç 14: –¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å metadata"""
        from src.config import get_config
        from src.data_loader import get_pdf_chunker
        
        config = get_config()
        pdf_dir = Path(config.data.pdf_path)
        
        if not pdf_dir.exists() or not list(pdf_dir.glob("*.pdf")):
            pytest.skip("‚ö†Ô∏è No PDFs")
        
        try:
            chunker = get_pdf_chunker()
            test_pdf = str(list(pdf_dir.glob("*.pdf"))[0])
            chunks = chunker.load_and_chunk_pdf(test_pdf)
            
            required_fields = {'book', 'page', 'chunk_index', 'chunk_id', 'char_count'}
            
            for chunk in chunks[:10]:
                meta_keys = set(chunk.metadata.keys())
                missing = required_fields - meta_keys
                assert not missing, f"Missing metadata fields: {missing}"
            
            logger.info(f"‚úÖ All chunks have required metadata fields: {required_fields}")
            
        except Exception as e:
            pytest.skip(f"Metadata test skipped: {e}")


# ============================================================================
# RUN
# ============================================================================

if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])