{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed63bc32",
   "metadata": {},
   "source": [
    "# Создание простой RAG системы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a792f1",
   "metadata": {},
   "source": [
    "Я реализую простую RAG систему как чат с электронным психологом. То есть за данные берем известные книги по психологии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee980c7c",
   "metadata": {},
   "source": [
    "## Шаг 1: Препроцессинг данных и создание эмбедингов\n",
    "План:\n",
    "1. Импорт pdf файлов\n",
    "2. Препроцессинг текста для эмбедингов (разделение на чанки)\n",
    "3. Эмбендинг чанков текста с помощью эмбендинговой модели\n",
    "4. Сохранение эмбендингов в файл"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd82b27",
   "metadata": {},
   "source": [
    "## 1. Импорт pdf файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e79d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] File exists. Skipping Allana-Piza-YAzyk-telodvizhenij...\n",
      "[INFO] File exists. Skipping Eric-Berne-games-that-people-play...\n",
      "[INFO] File exists. Skipping Goleman-D.-Emotional-Intelligence.-Why-it-may-be-more-important-than-IQ...\n",
      "[INFO] File exists. Skipping Gurina-Koshenova-Rabota-psikhologa-s_detskoi...\n",
      "[INFO] File exists. Skipping Psihology-Aykido...\n",
      "[INFO] File exists. Skipping Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauchitsya-ubezhdat-y-dobivatsya-uspeha...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "pdf_path = 'psichology books/'\n",
    "books = ['Allana-Piza-YAzyk-telodvizhenij', 'Eric-Berne-games-that-people-play', 'Goleman-D.-Emotional-Intelligence.-Why-it-may-be-more-important-than-IQ', 'Gurina-Koshenova-Rabota-psikhologa-s_detskoi', 'Psihology-Aykido', 'Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauchitsya-ubezhdat-y-dobivatsya-uspeha']\n",
    "\n",
    "for book in books:\n",
    "    if os.path.exists(pdf_path + book + '.pdf'):\n",
    "        print(f'[INFO] File exists. Skipping {book}...')\n",
    "    else:\n",
    "        print(f'[INFO] {book} is not found')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dbbd054",
   "metadata": {},
   "outputs": [],
   "source": [
    " #\\xa0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ce6d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3856390f6bb64d5bbbadd9edd5477158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a219dd6ade442d89fd1315d228aaf2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbc69e4a0374dbebf7f70d8bbe0310a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f9ce18c3524d4f950b9d6c0285ad17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe948d337684172af53eb5103524798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda796f7ce614065b263953e826c6b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1748"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def text_formatter(text : str) -> str:\n",
    "    \"\"\"Performs basic text formatting.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def open_and_read_pdf(file_path: str) -> list[str]:\n",
    "    doc = fitz.open(file_path)\n",
    "    pages_and_texts = []\n",
    "    for page_num, page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text(\"text\")\n",
    "        text = text_formatter(text=text)\n",
    "        if \"Goleman\" in file_path:\n",
    "            text = text.replace(\"\\xa0\", \" \")\n",
    "        pages_and_texts.append({\"book\": file_path[17:-4], \"page_num\": page_num, \"page_char_count\": len(text), \"page_word_count\": len(text.split()), \"page_token_count\": len(text)/4, \"text\": text})\n",
    "    return  pages_and_texts\n",
    "\n",
    "texts = []\n",
    "for book in books:\n",
    "    texts.extend(open_and_read_pdf(pdf_path + book + '.pdf'))\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac20557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences extracted: 27035\n"
     ]
    }
   ],
   "source": [
    "# Дополнительный препроцессинг текста\n",
    "\n",
    "import re\n",
    "from nltk import sent_tokenize  # Assuming NLTK is available or can be used; if not, implement custom sentence splitter\n",
    "\n",
    "# Additional preprocessing steps:\n",
    "# 1. Hyphen removal for word breaks: Merge words split by hyphens across lines, e.g., \"паци- ентам\" -> \"пациентам\". This uses regex to find patterns like \"word- \" followed by another word and joins them without the hyphen.\n",
    "# 2. Multiple spaces normalization: Replace multiple whitespace characters with a single space to clean up extra gaps.\n",
    "# 3. Remove special annotations: Strip out common footnote markers like \"— Примеч. пер.\" using regex patterns for known formats.\n",
    "# 4. Sentence tokenization: Split the cleaned text into individual sentences using NLTK's sent_tokenize, which handles Russian punctuation reasonably well. If NLTK isn't available, a custom regex-based splitter is provided as fallback.\n",
    "# 5. Lowercase normalization (optional): Convert text to lowercase for consistency, but can be skipped if case sensitivity is needed.\n",
    "# 6. Trim leading/trailing punctuation: Remove any leading or trailing non-alphabetic characters from sentences if they don't belong.\n",
    "\n",
    "def advanced_text_formatter(text: str) -> str:\n",
    "    \"\"\"Enhanced text formatting beyond basic.\"\"\"\n",
    "    # Step 1: Remove hyphens from word breaks\n",
    "    text = re.sub(r'(\\w+)-\\s+(\\w+)', r'\\1\\2', text)\n",
    "    \n",
    "    # Step 2: Normalize multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Step 3: Remove specific annotations like footnotes\n",
    "    text = re.sub(r'—\\s*Примеч\\.\\s*пер\\.\\s*', '', text)  # Target \"— Примеч. пер.\"\n",
    "    text = re.sub(r'\\(\\s*\\d+\\s*\\)\\.', '', text)  # Remove numbered lists like \"(1).\", \"(2).\" etc.\n",
    "    \n",
    "    # Step 4: Optional lowercase\n",
    "    # text = text.lower()  # Uncomment if needed\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Fallback sentence splitter if NLTK not available\n",
    "def custom_sent_tokenize(text: str) -> list[str]:\n",
    "    \"\"\"Custom regex-based sentence tokenizer for Russian text.\"\"\"\n",
    "    sentence_end = re.compile(r'(?<!\\w\\.\\w.)(?<![A-ZА-Я][a-zа-я]\\.)(?<=\\.|\\?|\\!|\\…)\\s')\n",
    "    sentences = sentence_end.split(text)\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "# Apply advanced formatting to existing texts\n",
    "for item in texts:\n",
    "    item['text'] = advanced_text_formatter(item['text'])\n",
    "\n",
    "# Now split into sentences\n",
    "sentences = []\n",
    "for item in texts:\n",
    "    # Use NLTK if available\n",
    "    try:\n",
    "        page_sentences = sent_tokenize(item['text'], language='russian')\n",
    "    except:\n",
    "        page_sentences = custom_sent_tokenize(item['text'])\n",
    "    \n",
    "    for sent in page_sentences:\n",
    "        # Step 6: Trim leading/trailing punctuation if unnecessary\n",
    "        sent = re.sub(r'^[^\\w]+', '', sent)  # Remove leading non-word chars\n",
    "        sent = re.sub(r'[^\\w]+$', '', sent)  # Remove trailing non-word chars\n",
    "        \n",
    "        sentences.append({\n",
    "            \"book\": item['book'],\n",
    "            \"page_num\": item['page_num'],\n",
    "            \"sentence\": sent,\n",
    "            \"sent_char_count\": len(sent),\n",
    "            \"sent_word_count\": len(sent.split()),\n",
    "            \"sent_token_count\": len(sent) / 4\n",
    "        })\n",
    "\n",
    "print(f\"Total sentences extracted: {len(sentences)}\")\n",
    "\n",
    "# Optionally, save to file or further process\n",
    "import json\n",
    "with open('processed_sentences.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sentences, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a782c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Психика и медицина 281 Глава 11 Психика и медицина «Кто научил вас этому всему, доктор?» Ответ последовал незамедлительно: «Страдание». Альбер Камю . Чума Непонятная тупая боль в паху погнала меня в больницу. Осмотр не выявил ничего необычного, пока врач не увидел результаты анализа мочи: в ней были обнаружены следы крови. — Я хочу, чтобы вы легли в больницу и прошли коекакие исследования. Надо проверить работу почек, сделать цитологию… — сказал он деловым тоном. Не помню, что он говорил дальше. Мое сознание, казалось, застыло на слове «цитология». Рак. У меня осталось смутное воспоминание, что он объяснял, где и когда я должен пройти диагностику. Простейшие указания, но даже их пришлось просить несколько раз повторить. «Цитология…» — мой ум не желал расставаться с этим словом. Оно вызвало у меня такое чувство, будто меня сзади схватили за горло и грабят на пороге собственного дома.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[700]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126f2690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>1</td>\n",
       "      <td>1378</td>\n",
       "      <td>182</td>\n",
       "      <td>344.50</td>\n",
       "      <td>Annotation Книга Аллана Пиза «Язык телодвижени...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>2</td>\n",
       "      <td>1021</td>\n",
       "      <td>138</td>\n",
       "      <td>255.25</td>\n",
       "      <td>Различие Пространственных Зон у Горожан и Жите...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>3</td>\n",
       "      <td>1052</td>\n",
       "      <td>142</td>\n",
       "      <td>263.00</td>\n",
       "      <td>Жест Скрещивание Рук, Усиленное Сжатием Пальце...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>4</td>\n",
       "      <td>902</td>\n",
       "      <td>112</td>\n",
       "      <td>225.50</td>\n",
       "      <td>Жесты, Используемые Мужчинами при Ухаживании Ж...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              book  page_num  page_char_count  \\\n",
       "0  Allana-Piza-YAzyk-telodvizhenij         0                0   \n",
       "1  Allana-Piza-YAzyk-telodvizhenij         1             1378   \n",
       "2  Allana-Piza-YAzyk-telodvizhenij         2             1021   \n",
       "3  Allana-Piza-YAzyk-telodvizhenij         3             1052   \n",
       "4  Allana-Piza-YAzyk-telodvizhenij         4              902   \n",
       "\n",
       "   page_word_count  page_token_count  \\\n",
       "0                0              0.00   \n",
       "1              182            344.50   \n",
       "2              138            255.25   \n",
       "3              142            263.00   \n",
       "4              112            225.50   \n",
       "\n",
       "                                                text  \n",
       "0                                                     \n",
       "1  Annotation Книга Аллана Пиза «Язык телодвижени...  \n",
       "2  Различие Пространственных Зон у Горожан и Жите...  \n",
       "3  Жест Скрещивание Рук, Усиленное Сжатием Пальце...  \n",
       "4  Жесты, Используемые Мужчинами при Ухаживании Ж...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(texts)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b187db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>187.05</td>\n",
       "      <td>1719.60</td>\n",
       "      <td>239.63</td>\n",
       "      <td>429.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>135.44</td>\n",
       "      <td>618.48</td>\n",
       "      <td>93.74</td>\n",
       "      <td>154.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.00</td>\n",
       "      <td>1514.25</td>\n",
       "      <td>211.00</td>\n",
       "      <td>378.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>161.00</td>\n",
       "      <td>1939.00</td>\n",
       "      <td>264.00</td>\n",
       "      <td>484.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>275.00</td>\n",
       "      <td>2102.00</td>\n",
       "      <td>288.00</td>\n",
       "      <td>525.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>544.00</td>\n",
       "      <td>3273.00</td>\n",
       "      <td>1386.00</td>\n",
       "      <td>818.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  page_char_count  page_word_count  page_token_count\n",
       "count   1748.00          1748.00          1748.00           1748.00\n",
       "mean     187.05          1719.60           239.63            429.90\n",
       "std      135.44           618.48            93.74            154.62\n",
       "min        0.00             0.00             0.00              0.00\n",
       "25%       74.00          1514.25           211.00            378.56\n",
       "50%      161.00          1939.00           264.00            484.75\n",
       "75%      275.00          2102.00           288.00            525.50\n",
       "max      544.00          3273.00          1386.00            818.25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63f00d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Это первое предложение., Это второе предложение!, А это третье предложение?]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.ru import Russian\n",
    "nlp = Russian()\n",
    "\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "doc = nlp('Это первое предложение. Это второе предложение! А это третье предложение?')\n",
    "assert len(list(doc.sents)) == 3\n",
    "\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edc6f559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e16a1ec94b4cb0b285589aa9cf2089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1748 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(texts):\n",
    "    item['sentences'] = list(nlp(item['text']).sents)\n",
    "\n",
    "    item['sentences'] = [str(sent) for sent in item['sentences']]\n",
    "\n",
    "    item['page_sentence_count_spacy'] = len(item['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e20771b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book': 'Goleman-D.-Emotional-Intelligence.-Why-it-may-be-more-important-than-IQ',\n",
       "  'page_num': 451,\n",
       "  'page_char_count': 1973,\n",
       "  'page_word_count': 263,\n",
       "  'page_token_count': 493.25,\n",
       "  'text': '452 Эмоциональная грамотность «Почтовый ящик» обеспечивает определенную маневренность, так как слишком жесткая повестка дня может полностью расходиться с реальностью. На обсуждение класса выносятся актуальные критические ситуации или спорные проблемы. По мере того как дети растут и меняются, меняются и насущные заботы. Для большей результативности уроки эмоциональной грамотности следует согласовывать с уровнем развития ребенка и в разном возрасте повторно преподавать их наиболее подходящим способом, соответствующим меняющемуся пониманию ученика и его проблемам. Но возникает вопрос: насколько рано нужно начинать? Некоторые специалисты считают, что более всего благотворны первые годы жизни. Педиатр из Гарвардского университета Томас Бразелтон уверен, что многим родителям полезно пройти специальную подготовку, чтобы стать эмоциональными наставниками своих малолетних детей. Это можно сделать в рамках курсов, когда для обучения специалисты приходят прямо домой. В программах подготовки к школе, таких как Head Start, необходимо более методично заниматься вопросами общения и самодисциплины. Как следует из главы 12, готовность к усвоению знаний в значительной мере зависит от наличия у детей хотя бы нескольких основных навыков эмоционального контроля. И дошкольный период чрезвычайно важен для их приобретения. Уже есть подтверждения тому, что Head Start, если все проходит нормально (кстати, очень важное замечание), часто оказывает длительное благотворное влияние в эмоциональном и социальном плане на жизнь тех, кто окончил курс, что проявляется даже после совершеннолетия. У таких детей меньше проблем с наркотиками и соблюдением закона, более удачные браки и выше профессиональная квалификация, обеспечивающая неплохой заработок5. Такого рода вмешательства срабатывают наилучшим образом, если следуют эмоциональному графику развития ребенка6. Судя по воп лям новорожденных, дети испытывают сильные чувства с момента',\n",
       "  'sentences': ['452 Эмоциональная грамотность «Почтовый ящик» обеспечивает определенную маневренность, так как слишком жесткая повестка дня может полностью расходиться с реальностью.',\n",
       "   'На обсуждение класса выносятся актуальные критические ситуации или спорные проблемы.',\n",
       "   'По мере того как дети растут и меняются, меняются и насущные заботы.',\n",
       "   'Для большей результативности уроки эмоциональной грамотности следует согласовывать с уровнем развития ребенка и в разном возрасте повторно преподавать их наиболее подходящим способом, соответствующим меняющемуся пониманию ученика и его проблемам.',\n",
       "   'Но возникает вопрос: насколько рано нужно начинать?',\n",
       "   'Некоторые специалисты считают, что более всего благотворны первые годы жизни.',\n",
       "   'Педиатр из Гарвардского университета Томас Бразелтон уверен, что многим родителям полезно пройти специальную подготовку, чтобы стать эмоциональными наставниками своих малолетних детей.',\n",
       "   'Это можно сделать в рамках курсов, когда для обучения специалисты приходят прямо домой.',\n",
       "   'В программах подготовки к школе, таких как Head Start, необходимо более методично заниматься вопросами общения и самодисциплины.',\n",
       "   'Как следует из главы 12, готовность к усвоению знаний в значительной мере зависит от наличия у детей хотя бы нескольких основных навыков эмоционального контроля.',\n",
       "   'И дошкольный период чрезвычайно важен для их приобретения.',\n",
       "   'Уже есть подтверждения тому, что Head Start, если все проходит нормально (кстати, очень важное замечание), часто оказывает длительное благотворное влияние в эмоциональном и социальном плане на жизнь тех, кто окончил курс, что проявляется даже после совершеннолетия.',\n",
       "   'У таких детей меньше проблем с наркотиками и соблюдением закона, более удачные браки и выше профессиональная квалификация, обеспечивающая неплохой заработок5.',\n",
       "   'Такого рода вмешательства срабатывают наилучшим образом, если следуют эмоциональному графику развития ребенка6.',\n",
       "   'Судя по воп лям новорожденных, дети испытывают сильные чувства с момента'],\n",
       "  'page_sentence_count_spacy': 15}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d52a0caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>187.05</td>\n",
       "      <td>1719.60</td>\n",
       "      <td>239.63</td>\n",
       "      <td>429.90</td>\n",
       "      <td>14.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>135.44</td>\n",
       "      <td>618.48</td>\n",
       "      <td>93.74</td>\n",
       "      <td>154.62</td>\n",
       "      <td>8.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.00</td>\n",
       "      <td>1514.25</td>\n",
       "      <td>211.00</td>\n",
       "      <td>378.56</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>161.00</td>\n",
       "      <td>1939.00</td>\n",
       "      <td>264.00</td>\n",
       "      <td>484.75</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>275.00</td>\n",
       "      <td>2102.00</td>\n",
       "      <td>288.00</td>\n",
       "      <td>525.50</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>544.00</td>\n",
       "      <td>3273.00</td>\n",
       "      <td>1386.00</td>\n",
       "      <td>818.25</td>\n",
       "      <td>73.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  page_char_count  page_word_count  page_token_count  \\\n",
       "count   1748.00          1748.00          1748.00           1748.00   \n",
       "mean     187.05          1719.60           239.63            429.90   \n",
       "std      135.44           618.48            93.74            154.62   \n",
       "min        0.00             0.00             0.00              0.00   \n",
       "25%       74.00          1514.25           211.00            378.56   \n",
       "50%      161.00          1939.00           264.00            484.75   \n",
       "75%      275.00          2102.00           288.00            525.50   \n",
       "max      544.00          3273.00          1386.00            818.25   \n",
       "\n",
       "       page_sentence_count_spacy  \n",
       "count                    1748.00  \n",
       "mean                       14.68  \n",
       "std                         8.53  \n",
       "min                         0.00  \n",
       "25%                        10.00  \n",
       "50%                        14.00  \n",
       "75%                        18.00  \n",
       "max                        73.00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(texts)\n",
    "data.describe().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d76a414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunking with spacy sentences (1 chunk = ?10? sentences). \n",
    "\n",
    "num_sentences_per_chunk = 10\n",
    "\n",
    "def split_list(input_list: list[str], slice_size: int=num_sentences_per_chunk) -> list[list[str]]:\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "test_list = list(range(25))\n",
    "split_list(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6db939a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e98f93b19a41baaf984abafe0cf522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1748 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5d396234404224a248b6366017a087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2566"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "all_sentences = []\n",
    "for item in tqdm(texts):\n",
    "    for sent in item['sentences']:\n",
    "        all_sentences.append({\n",
    "            \"sentence\": str(sent),\n",
    "            \"book\": item['book'],\n",
    "            \"page_num\": item['page_num']\n",
    "        })\n",
    "\n",
    "\n",
    "sentence_chunks = split_list(all_sentences, slice_size=num_sentences_per_chunk)\n",
    "\n",
    "\n",
    "pages_and_chunks = []\n",
    "for chunk in tqdm(sentence_chunks):\n",
    "    chunk_dict = {}\n",
    "    chunk_dict['book'] = chunk[0]['book']\n",
    "    chunk_dict['page_num'] = chunk[0]['page_num']\n",
    "    \n",
    "    # Join the sentences in the chunk\n",
    "    joined_sentence_chunk = \" \".join([item['sentence'] for item in chunk]).replace(\"  \", \" \").strip()\n",
    "    joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk)\n",
    "    chunk_dict['sentence_text'] = joined_sentence_chunk\n",
    "    \n",
    "    # Recalculate stats for the new chunk\n",
    "    chunk_dict['chunk_char_count'] = len(joined_sentence_chunk)\n",
    "    chunk_dict['chunk_word_count'] = len(joined_sentence_chunk.split(\" \"))\n",
    "    chunk_dict['chunk_token_count'] = len(joined_sentence_chunk) / 4\n",
    "    \n",
    "    pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f1748da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book': 'Gurina-Koshenova-Rabota-psikhologa-s_detskoi',\n",
       "  'page_num': 70,\n",
       "  'page_char_count': 2184,\n",
       "  'page_word_count': 295,\n",
       "  'page_token_count': 546.0,\n",
       "  'text': '71 была создана самой природой по ряду рациональных причин: вопервых, она является последней, предсмертной попыткой жертвы спастись (животное «притворяется» мертвым, что часто приводит к изменению поведения хищника, и жертва имеет шанс спастись); вовторых, замерев, животное попадает в измененное состояние сознания, в котором не переживает столь болезненных ощущений. Однако здесь П. Левин подчеркивает большую разницу между иммобилизацией животных и человека: замерев, животное выжидает, когда минует опасность, а затем обязательно реализует скопившуюся энергию через интенсивные действия (бег, дрожь и другое), человек же после столкновения с угрозой не всегда прибегает к разрядке. Именно в случае, когда человек не в состоянии завершить полный процесс иммобилизации – входа в это состояние «замороженности», пребывания в нем и успешного выхода, – у него формируются долгосрочные, тревожные, мешающие вести привычный образ жизни симптомы ПТСР. Одна из причин того, почему люди не могут, как и животные, естественно порождать и завершать различные инстинктивные реакции, связана с неокортиксом – высокоразвитой корой головного мозга, которой обладает лишь человек. Неокортекс (рациональный мозг) по своей структуре является очень сложным и обладает столь сильным воздействием, что может препятствовать формированию инстинктивных восстановительных импульсов и реакций, за которые отвечает рептильный (животный) мозг. П. Левин считает, что именно развитая кора головного мозга с легкостью подавляет некоторые из слабых инстинктивных реакций, к которым можно отнести и реакции, управляющие восстановительным процессом после травмы с помощью энергетической разрядки. В случае, если неокортекс оказался сильнее животных инстинктов, человек получает травму. Однако П. Левин уверяет, что завершить процесс отреагирования на угрозу можно и спустя годы, для этого он предлагает свой метод. П. Левин отмечает, травма – это не всегда страшное и выходящее из ряда повседневности событие: травму может запустить любое событие, связанное с субъективным чувством опасности и невозможностью разрядить нервное перевозбуждение, например, стандартные',\n",
       "  'sentences': ['71 была создана самой природой по ряду рациональных причин: вопервых, она является последней, предсмертной попыткой жертвы спастись (животное «притворяется» мертвым, что часто приводит к изменению поведения хищника, и жертва имеет шанс спастись); вовторых, замерев, животное попадает в измененное состояние сознания, в котором не переживает столь болезненных ощущений.',\n",
       "   'Однако здесь П. Левин подчеркивает большую разницу между иммобилизацией животных и человека: замерев, животное выжидает, когда минует опасность, а затем обязательно реализует скопившуюся энергию через интенсивные действия (бег, дрожь и другое), человек же после столкновения с угрозой не всегда прибегает к разрядке.',\n",
       "   'Именно в случае, когда человек не в состоянии завершить полный процесс иммобилизации – входа в это состояние «замороженности», пребывания в нем и успешного выхода, – у него формируются долгосрочные, тревожные, мешающие вести привычный образ жизни симптомы ПТСР.',\n",
       "   'Одна из причин того, почему люди не могут, как и животные, естественно порождать и завершать различные инстинктивные реакции, связана с неокортиксом – высокоразвитой корой головного мозга, которой обладает лишь человек.',\n",
       "   'Неокортекс (рациональный мозг) по своей структуре является очень сложным и обладает столь сильным воздействием, что может препятствовать формированию инстинктивных восстановительных импульсов и реакций, за которые отвечает рептильный (животный) мозг.',\n",
       "   'П. Левин считает, что именно развитая кора головного мозга с легкостью подавляет некоторые из слабых инстинктивных реакций, к которым можно отнести и реакции, управляющие восстановительным процессом после травмы с помощью энергетической разрядки.',\n",
       "   'В случае, если неокортекс оказался сильнее животных инстинктов, человек получает травму.',\n",
       "   'Однако П. Левин уверяет, что завершить процесс отреагирования на угрозу можно и спустя годы, для этого он предлагает свой метод.',\n",
       "   'П. Левин отмечает, травма – это не всегда страшное и выходящее из ряда повседневности событие: травму может запустить любое событие, связанное с субъективным чувством опасности и невозможностью разрядить нервное перевозбуждение, например, стандартные'],\n",
       "  'page_sentence_count_spacy': 9}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cf0f228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>187.05</td>\n",
       "      <td>1719.60</td>\n",
       "      <td>239.63</td>\n",
       "      <td>429.90</td>\n",
       "      <td>14.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>135.44</td>\n",
       "      <td>618.48</td>\n",
       "      <td>93.74</td>\n",
       "      <td>154.62</td>\n",
       "      <td>8.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.00</td>\n",
       "      <td>1514.25</td>\n",
       "      <td>211.00</td>\n",
       "      <td>378.56</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>161.00</td>\n",
       "      <td>1939.00</td>\n",
       "      <td>264.00</td>\n",
       "      <td>484.75</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>275.00</td>\n",
       "      <td>2102.00</td>\n",
       "      <td>288.00</td>\n",
       "      <td>525.50</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>544.00</td>\n",
       "      <td>3273.00</td>\n",
       "      <td>1386.00</td>\n",
       "      <td>818.25</td>\n",
       "      <td>73.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  page_char_count  page_word_count  page_token_count  \\\n",
       "count   1748.00          1748.00          1748.00           1748.00   \n",
       "mean     187.05          1719.60           239.63            429.90   \n",
       "std      135.44           618.48            93.74            154.62   \n",
       "min        0.00             0.00             0.00              0.00   \n",
       "25%       74.00          1514.25           211.00            378.56   \n",
       "50%      161.00          1939.00           264.00            484.75   \n",
       "75%      275.00          2102.00           288.00            525.50   \n",
       "max      544.00          3273.00          1386.00            818.25   \n",
       "\n",
       "       page_sentence_count_spacy  \n",
       "count                    1748.00  \n",
       "mean                       14.68  \n",
       "std                         8.53  \n",
       "min                         0.00  \n",
       "25%                        10.00  \n",
       "50%                        14.00  \n",
       "75%                        18.00  \n",
       "max                        73.00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd9733da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3ec45ee88444caa7fedcb720d62835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1748 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae25da30f25f42b2915c1aa52e05bb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1748 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3427"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "num_sentences_per_chunk = 10\n",
    "def split_list(input_list: list, slice_size: int = num_sentences_per_chunk) -> list[list]:\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "for item in tqdm(texts):\n",
    "    if 'sentences' in item:\n",
    "        item['sentence_chunks'] = split_list(item['sentences'])\n",
    "        item['num_chunks'] = len(item['sentence_chunks'])\n",
    "\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(texts):\n",
    "    if 'sentence_chunks' in item:\n",
    "        for sentence_chunk in item['sentence_chunks']:\n",
    "            chunk_dict = {}\n",
    "            chunk_dict['book'] = item['book']\n",
    "            chunk_dict['page_num'] = item['page_num']\n",
    "            joined_sentence_chunk = ' '.join(map(str, sentence_chunk)).replace(\"  \", \" \").strip()\n",
    "            joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk)\n",
    "            chunk_dict['sentence_text'] = joined_sentence_chunk\n",
    "            \n",
    "            chunk_dict['chunk_char_count'] = len(joined_sentence_chunk)\n",
    "            chunk_dict['chunk_word_count'] = len(joined_sentence_chunk.split(\" \"))\n",
    "            chunk_dict['chunk_token_count'] = len(joined_sentence_chunk)/4\n",
    "\n",
    "            pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67ec6ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book': 'Eric-Berne-games-that-people-play',\n",
       "  'page_num': 55,\n",
       "  'sentence_text': 'Глава 5. Игры 55 B. Наконец, игра третьей степени — это игра безудержная; доведённая до конца, она завершается в больнице, в суде или морге. Игры можно классифицировать также и по другим специфическим признакам, указанным при анализе ВИТ: по целям, ролям, наиболее очевидным преимуществам. Для систематической научной классификации наиболее подходящей может оказаться, вероятно, экзистенциальная точка зрения; но поскольку этот фактор ещё недостаточно изучен, такую классификацию придётся отложить на будущее. За неимением её, в настоящее время самой удобной классификацией представляется социологическая, которой мы и будем придерживаться в следующей части. Примечания Необходимо отметить заслуги Стивена Поттера с его чутким, пронизанным юмором анализом манёвров или “проделок” в повседневных жизненных ситуациях [2], и Дж. Г. Мида, пионера в исследовании общественной роли игр [3]. Игры, ведущие к психиатрическим расстройствам, систематически изучались на Сан-Францисских семинарах по социальной психиатрии, начиная с 1958 года; недавно этому разделу анализа игр посвятил свою книгу Т. Сас [4]. Роль игр в групповых процессах изучена в книге автора по групповой динамике [5]. Библиография 1.',\n",
       "  'chunk_char_count': 1195,\n",
       "  'chunk_word_count': 161,\n",
       "  'chunk_token_count': 298.75}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16226e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>187.05</td>\n",
       "      <td>1719.60</td>\n",
       "      <td>239.63</td>\n",
       "      <td>429.90</td>\n",
       "      <td>14.68</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>135.44</td>\n",
       "      <td>618.48</td>\n",
       "      <td>93.74</td>\n",
       "      <td>154.62</td>\n",
       "      <td>8.53</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.00</td>\n",
       "      <td>1514.25</td>\n",
       "      <td>211.00</td>\n",
       "      <td>378.56</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>161.00</td>\n",
       "      <td>1939.00</td>\n",
       "      <td>264.00</td>\n",
       "      <td>484.75</td>\n",
       "      <td>14.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>275.00</td>\n",
       "      <td>2102.00</td>\n",
       "      <td>288.00</td>\n",
       "      <td>525.50</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>544.00</td>\n",
       "      <td>3273.00</td>\n",
       "      <td>1386.00</td>\n",
       "      <td>818.25</td>\n",
       "      <td>73.00</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  page_char_count  page_word_count  page_token_count  \\\n",
       "count   1748.00          1748.00          1748.00           1748.00   \n",
       "mean     187.05          1719.60           239.63            429.90   \n",
       "std      135.44           618.48            93.74            154.62   \n",
       "min        0.00             0.00             0.00              0.00   \n",
       "25%       74.00          1514.25           211.00            378.56   \n",
       "50%      161.00          1939.00           264.00            484.75   \n",
       "75%      275.00          2102.00           288.00            525.50   \n",
       "max      544.00          3273.00          1386.00            818.25   \n",
       "\n",
       "       page_sentence_count_spacy  num_chunks  \n",
       "count                    1748.00     1748.00  \n",
       "mean                       14.68        1.96  \n",
       "std                         8.53        0.88  \n",
       "min                         0.00        0.00  \n",
       "25%                        10.00        1.00  \n",
       "50%                        14.00        2.00  \n",
       "75%                        18.00        2.00  \n",
       "max                        73.00        8.00  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8565c0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3427.00</td>\n",
       "      <td>3427.00</td>\n",
       "      <td>3427.00</td>\n",
       "      <td>3427.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>191.52</td>\n",
       "      <td>862.12</td>\n",
       "      <td>118.67</td>\n",
       "      <td>215.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>142.89</td>\n",
       "      <td>505.03</td>\n",
       "      <td>67.04</td>\n",
       "      <td>126.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>70.50</td>\n",
       "      <td>453.00</td>\n",
       "      <td>63.00</td>\n",
       "      <td>113.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>159.00</td>\n",
       "      <td>806.00</td>\n",
       "      <td>114.00</td>\n",
       "      <td>201.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>286.00</td>\n",
       "      <td>1260.00</td>\n",
       "      <td>173.00</td>\n",
       "      <td>315.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>543.00</td>\n",
       "      <td>2214.00</td>\n",
       "      <td>293.00</td>\n",
       "      <td>553.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count   3427.00           3427.00           3427.00            3427.00\n",
       "mean     191.52            862.12            118.67             215.53\n",
       "std      142.89            505.03             67.04             126.26\n",
       "min        0.00              2.00              1.00               0.50\n",
       "25%       70.50            453.00             63.00             113.25\n",
       "50%      159.00            806.00            114.00             201.50\n",
       "75%      286.00           1260.00            173.00             315.00\n",
       "max      543.00           2214.00            293.00             553.50"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41c213da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 21.0 | Text: Наилучшие результаты достигаются, когда школьные уроки координируются с происходящим\n",
      "Chunk token count: 25.5 | Text: Какие факторы срабатывают, например, когда люди с высоким IQ терпят неудачу, а обладатели относительно\n",
      "Chunk token count: 6.0 | Text: Какое храброе животное —\n",
      "Chunk token count: 11.0 | Text: Наконец, он отстаивает своё отношение к кре-\n",
      "Chunk token count: 0.75 | Text: 267\n"
     ]
    }
   ],
   "source": [
    "min_token_length = 30\n",
    "for row in df[df['chunk_token_count'] <= min_token_length].sample(5).iterrows():\n",
    "\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3908627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book': 'Allana-Piza-YAzyk-telodvizhenij',\n",
       "  'page_num': 17,\n",
       "  'sentence_text': 'Конгруэнтность — Совпадение Слов и Жестов Если бы вы были собеседником человека, показанного на рис. 4, и попросили его выразить свое мнение относительно того, что вы только что сказали, на что он бы ответил, что с вами не согласен, то его невербальные сигналы были бы конгруэнтными, т.е. соответ-ствовали бы его словесным высказываниям. Если же он скажет, что ему очень нравится все, что вы говорите, он будет лгать, потому что его слова и жесты будут не конгруэнтными. Исследования доказывают, что невербальные сигналы несут в 5 раз больше информации, чем вербальные, и в случае, если сигналы не — конгруэнтны, люди полагаются на невербальную информацию, предпочитая ее словесной. Часто можно наблюдать, как какой-нибудь политик стоит на трибуне, крепко скрестив руки на груди ( защитная поза ) с опущенным подбородком ( критическая или враждебная поза), и говорит аудитории о том, как восприимчиво и дружелюбно он относится к идеям молодежи. Он может попытаться убедить аудиторию в своем теплом, гуманном отношении, делая быстрые, резкие удары по трибуне. Зигмунд Фрейд однажды заметил, что когда одна пациентка словесно убеждала его в том, что она счастлива в браке, она бессознательно снимала с пальца и надевала обручальное кольцо. Фрейд понял значение этого непроизвольного жеста и не удивился, когда стали обозначаться семейные проблемы этой пациентки.',\n",
       "  'chunk_char_count': 1360,\n",
       "  'chunk_word_count': 204,\n",
       "  'chunk_token_count': 340.0},\n",
       " {'book': 'Allana-Piza-YAzyk-telodvizhenij',\n",
       "  'page_num': 18,\n",
       "  'sentence_text': 'Ключом к правильной интерпретации жестов является учитывание всей совокупности жестов и конгруэнтность вербальных и невербальных сигналов.',\n",
       "  'chunk_char_count': 138,\n",
       "  'chunk_word_count': 16,\n",
       "  'chunk_token_count': 34.5},\n",
       " {'book': 'Allana-Piza-YAzyk-telodvizhenij',\n",
       "  'page_num': 19,\n",
       "  'sentence_text': 'Значение Контекста для Толкования Жестов Кроме учета совокупности жестов и соответствия между словами и телодвижениями, для правильной интерпретации жестов необходимо учитывать контекст, в котором живут эти жесты. Если вы, например, в холодный зимний день увидите на автобусной остановке человека, сидящего со скрещенными ногами, крепко скрещенными на груди руками и опущенной вниз головой, то это скорее всего будет означать, что он замерз, а вовсе не его критическое отношение к чему-либо. Однако, если человек в точно таком же положении будет сидеть напротив вас за столом переговоров о заключении сделки, то его жесты совершенно определенно следует трактовать как имеющие негативное или оборонительное отношение в сложившейся ситуации. В этой книге все жесты будут рассматриваться с учетом окружающей ситуации, и, при возможности, рассмотрится совокуп-ность жестов в контексте.',\n",
       "  'chunk_char_count': 881,\n",
       "  'chunk_word_count': 122,\n",
       "  'chunk_token_count': 220.25},\n",
       " {'book': 'Allana-Piza-YAzyk-telodvizhenij',\n",
       "  'page_num': 20,\n",
       "  'sentence_text': 'Другие Факторы, Оказывающие Влияние на Интерпретацию Жестов Если у человека слабое рукопожатие, то можно сделать вывод о слабости его характера, и в главе об особенностях рукопожатия мы исследуем причины, объясняющие это утверждение. Но если у человека артрит суставов руки, то он будет использовать слабое рукопожатие, чтобы предохранить руку от боли. Поэтому художники, музыканты, хирурги и люди других деликатных профессий, где требуются чуткие пальцы, обычно предпочитают не обмениваться рукопожатиями, но если они вынуждены это делать, то пользуются щадящим рукопожатием. Иногда люди, носящие плохо сидящую или тесную одежду, скованы в своих движениях, и это оказывает влияние на выразительность их языка тела. Это достаточно редкие случаи, но их важно иметь в виду, чтобы понять, какое психологическое влияние имеют такие вещи на боди лэнгвидж.',\n",
       "  'chunk_char_count': 850,\n",
       "  'chunk_word_count': 120,\n",
       "  'chunk_token_count': 212.5},\n",
       " {'book': 'Allana-Piza-YAzyk-telodvizhenij',\n",
       "  'page_num': 21,\n",
       "  'sentence_text': 'Положение в Обществе и Богатство Жестикуляции Научные исследования в области лингвистики показали, что существует прямая зависимость между социальным статусом, властью и престижем человека и его словарным запасом. Другими словами, чем выше социальное или профессиональное положение человека, тем лучше его способность общаться на уровне слов и фраз. Исследования в области невербалики выявили зависимость между красноречивостью человека и степенью жестикуляции, используемой человеком для передачи смысла своих сообщений. Это означает, что существует прямая зависимость между социальным положением человека, его престижем и количеством жестов и телодвижений, Которыми он пользуется. Человек, находящийся на вершине соци-альной лестницы или профессиональной карьеры, может пользоваться богатством своего словарного запаса в процессе коммуникации, в то время как менее образованный или менее профессиональный человек будет чаще полагаться на жесты, а не на слова в процессе общения. В этой книге большинство примеров описывает поведение людей среднего сословия, но общее правило заключается в том, что чем выше социально-экономическое положение человека, тем менее развита у него жестикуляция и беднее телодвижения. Быстрота некоторых жестов и их очевидность для глаза зависит от возраста человека. Например, если 5-летний ребенок скажет неправду своим родителям, то сразу же после этого он прикроет одной или обеими руками рот (рис. 5). Этот жест «прикрывание рта рукой» подскажет родителям о том, что ребенок солгал, но на протяжении всей своей жизни человек использует этот жест, когда он лжет, обычно меняется только скорость совершения этого жеста.',\n",
       "  'chunk_char_count': 1651,\n",
       "  'chunk_word_count': 222,\n",
       "  'chunk_token_count': 412.75}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df['chunk_token_count'] > min_token_length].to_dict(orient='records')\n",
    "pages_and_chunks_over_min_token_len[20:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89efb2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book': 'Goleman-D.-Emotional-Intelligence.-Why-it-may-be-more-important-than-IQ',\n",
       "  'page_num': 35,\n",
       "  'sentence_text': '36 Эмоциональный мозг Два наших ума Приятельница рассказала о мучительном разводе с мужем: он влюбился в молодую женщину и внезапно объявил, что уходит. За этим последовали месяцы ожесточенных споров о доме, деньгах и детях. Прошло время, и она стала говорить, что ей нравится независимость и возможность быть самой себе хозяйкой. « Я больше не думаю о нем — он мне абсолютно безразличен», — вымолвила она. Но в ее глазах стояли слезы. Слезы, на мгновение наполнившие глаза, вполне могли остаться незамеченными. Но эмпатическое понимание — затуманенный влагой взгляд означает, что человек опечален, хотя слова и говорят об обратном, — это такой же способ коммуникации, как и чтение напечатанного текста. В одном случае это дело эмоционального интеллекта, в другом — рационального. По сути, у нас два ума: один думает, другой чувствует. Из взаимодействия этих двух коренным образом различающихся процессов познания складывается наша психическая деятельность.',\n",
       "  'chunk_char_count': 957,\n",
       "  'chunk_word_count': 142,\n",
       "  'chunk_token_count': 239.25}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks_over_min_token_len, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536437e",
   "metadata": {},
   "source": [
    "## Эмбендинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bee93fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Своевременное управление своими эмоциями помогает человеку лучше адаптироваться в обществе и достигать успехов в различных сферах жизни.\n",
      "Embedding: [ 0.01369482 -0.03131527  0.01164841 -0.04669845 -0.01688643]\n",
      "\n",
      "Sentence: Эмоциональный интеллект включает в себя способность распознавать, понимать и управлять своими эмоциями, а также эмоциями других людей.\n",
      "Embedding: [ 0.03207109 -0.08083745  0.02561147 -0.01334221 -0.00197688]\n",
      "\n",
      "Sentence: Мне нравятся лошади\n",
      "Embedding: [ 0.01926965  0.05492534  0.0095705  -0.00352864  0.02221948]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path='all-mpnet-base-v2', device='cpu')\n",
    "\n",
    "sentences = [\"Своевременное управление своими эмоциями помогает человеку лучше адаптироваться в обществе и достигать успехов в различных сферах жизни.\", \n",
    "             \"Эмоциональный интеллект включает в себя способность распознавать, понимать и управлять своими эмоциями, а также эмоциями других людей.\",\n",
    "             \"Мне нравятся лошади\"]\n",
    "\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "embeddings_dictionary = dict(zip(sentences, embeddings))\n",
    "\n",
    "for sentence, embedding in embeddings_dictionary.items():\n",
    "    print(f'Sentence: {sentence}\\nEmbedding: {embedding[:5]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad5ce34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63f205",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "embedding_model.to('cpu')\n",
    "\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item['embedding'] = embedding_model.encode(item['sentence_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd2032e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4963a51b7d4ee8991661f34a826a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embedding_model.to('cuda')\n",
    "\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item['embedding'] = embedding_model.encode(item['sentence_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f9c7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Глава 5. Игры 55 B. Наконец, игра третьей степени — это игра безудержная; доведённая до конца, она завершается в больнице, в суде или морге. Игры можно классифицировать также и по другим специфическим признакам, указанным при анализе ВИТ: по целям, ролям, наиболее очевидным преимуществам. Для систематической научной классификации наиболее подходящей может оказаться, вероятно, экзистенциальная точка зрения; но поскольку этот фактор ещё недостаточно изучен, такую классификацию придётся отложить на будущее. За неимением её, в настоящее время самой удобной классификацией представляется социологическая, которой мы и будем придерживаться в следующей части. Примечания Необходимо отметить заслуги Стивена Поттера с его чутким, пронизанным юмором анализом манёвров или “проделок” в повседневных жизненных ситуациях [2], и Дж. Г. Мида, пионера в исследовании общественной роли игр [3]. Игры, ведущие к психиатрическим расстройствам, систематически изучались на Сан-Францисских семинарах по социальной психиатрии, начиная с 1958 года; недавно этому разделу анализа игр посвятил свою книгу Т. Сас [4]. Роль игр в групповых процессах изучена в книге автора по групповой динамике [5]. Библиография 1.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "embedding_model.to('cuda')\n",
    "\n",
    "text_chunks = [item[\"sentence_text\"] for item in pages_and_chunks_over_min_token_len]\n",
    "text_chunks[419]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fddf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3245"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4297c620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 54s\n",
      "Wall time: 32.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0655, -0.0385,  0.0090,  ...,  0.0244, -0.0035, -0.0483],\n",
       "        [ 0.0653,  0.0057,  0.0079,  ...,  0.0562, -0.0214, -0.0263],\n",
       "        [ 0.0674, -0.0314,  0.0212,  ...,  0.0540, -0.0454, -0.0211],\n",
       "        ...,\n",
       "        [ 0.0297, -0.0204, -0.0157,  ...,  0.0394, -0.0548, -0.0257],\n",
       "        [ 0.0318, -0.0376, -0.0163,  ...,  0.0539, -0.0398, -0.0362],\n",
       "        [ 0.0436, -0.0009,  0.0180,  ...,  0.0112, -0.0471, -0.0267]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text_chunk_embeddings = embedding_model.encode(text_chunks, batch_size=32, convert_to_tensor=True)\n",
    "\n",
    "text_chunk_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f5d146",
   "metadata": {},
   "source": [
    "## Сохранение эмбеддингов в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce7d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = 'text_chunks_and_embeddings_df.csv'\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96edafc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>page_num</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>1</td>\n",
       "      <td>Annotation Книга Аллана Пиза «Язык телодвижени...</td>\n",
       "      <td>1377</td>\n",
       "      <td>183</td>\n",
       "      <td>344.25</td>\n",
       "      <td>[ 6.55286983e-02 -3.84550951e-02  9.00769792e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>2</td>\n",
       "      <td>Различие Пространственных Зон у Горожан и Жите...</td>\n",
       "      <td>1021</td>\n",
       "      <td>138</td>\n",
       "      <td>255.25</td>\n",
       "      <td>[ 6.53100088e-02  5.69840986e-03  7.93763995e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>3</td>\n",
       "      <td>Жест Скрещивание Рук, Усиленное Сжатием Пальце...</td>\n",
       "      <td>1052</td>\n",
       "      <td>142</td>\n",
       "      <td>263.00</td>\n",
       "      <td>[ 6.74133077e-02 -3.14203836e-02  2.11770087e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>4</td>\n",
       "      <td>Жесты, Используемые Мужчинами при Ухаживании Ж...</td>\n",
       "      <td>893</td>\n",
       "      <td>112</td>\n",
       "      <td>223.25</td>\n",
       "      <td>[ 4.04209048e-02  1.23598920e-02  7.03040231e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>5</td>\n",
       "      <td>Как Ступени Ног Выражают Заинтересованность Ра...</td>\n",
       "      <td>764</td>\n",
       "      <td>103</td>\n",
       "      <td>191.00</td>\n",
       "      <td>[ 6.96066543e-02  1.39050819e-02  2.67599560e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              book  page_num  \\\n",
       "0  Allana-Piza-YAzyk-telodvizhenij         1   \n",
       "1  Allana-Piza-YAzyk-telodvizhenij         2   \n",
       "2  Allana-Piza-YAzyk-telodvizhenij         3   \n",
       "3  Allana-Piza-YAzyk-telodvizhenij         4   \n",
       "4  Allana-Piza-YAzyk-telodvizhenij         5   \n",
       "\n",
       "                                       sentence_text  chunk_char_count  \\\n",
       "0  Annotation Книга Аллана Пиза «Язык телодвижени...              1377   \n",
       "1  Различие Пространственных Зон у Горожан и Жите...              1021   \n",
       "2  Жест Скрещивание Рук, Усиленное Сжатием Пальце...              1052   \n",
       "3  Жесты, Используемые Мужчинами при Ухаживании Ж...               893   \n",
       "4  Как Ступени Ног Выражают Заинтересованность Ра...               764   \n",
       "\n",
       "   chunk_word_count  chunk_token_count  \\\n",
       "0               183             344.25   \n",
       "1               138             255.25   \n",
       "2               142             263.00   \n",
       "3               112             223.25   \n",
       "4               103             191.00   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 6.55286983e-02 -3.84550951e-02  9.00769792e-...  \n",
       "1  [ 6.53100088e-02  5.69840986e-03  7.93763995e-...  \n",
       "2  [ 6.74133077e-02 -3.14203836e-02  2.11770087e-...  \n",
       "3  [ 4.04209048e-02  1.23598920e-02  7.03040231e-...  \n",
       "4  [ 6.96066543e-02  1.39050819e-02  2.67599560e-...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df_save_path = 'text_chunks_and_embeddings_df.csv'\n",
    "text_chunks_and_embeddings_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embeddings_df_load.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57d15b6",
   "metadata": {},
   "source": [
    "Если бы у меня была действительно большая база данных эмбэндингов (100K - 1M) то тогда бы использовала векторную базу данных qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2580fbb",
   "metadata": {},
   "source": [
    "# Поиск и ответы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346d055",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m device = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m text_chunks_and_embeddings_df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mtext_chunks_and_embeddings_df.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m text_chunks_and_embeddings_df[\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mtext_chunks_and_embeddings_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43membedding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromstring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m[]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m embeddings = torch.tensor(np.stack(text_chunks_and_embeddings_df[\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m].tolist(), axis=\u001b[32m0\u001b[39m), dtype=torch.float32).to(device)\n\u001b[32m     14\u001b[39m pages_and_chunks = text_chunks_and_embeddings_df.to_dict(orient=\u001b[33m'\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Delta-Game\\simple-local-rag\\venv\\Lib\\site-packages\\pandas\\core\\series.py:4915\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4780\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4781\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4782\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4787\u001b[39m     **kwargs,\n\u001b[32m   4788\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4789\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4790\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4791\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4906\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4907\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4908\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4909\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4910\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4911\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4912\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4913\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4914\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4915\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Delta-Game\\simple-local-rag\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Delta-Game\\simple-local-rag\\venv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Delta-Game\\simple-local-rag\\venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Delta-Game\\simple-local-rag\\venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      5\u001b[39m device = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m text_chunks_and_embeddings_df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mtext_chunks_and_embeddings_df.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m text_chunks_and_embeddings_df[\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m] = text_chunks_and_embeddings_df[\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np.fromstring(\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33m[]\u001b[39m\u001b[33m\"\u001b[39m), sep=\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     12\u001b[39m embeddings = torch.tensor(np.stack(text_chunks_and_embeddings_df[\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m].tolist(), axis=\u001b[32m0\u001b[39m), dtype=torch.float32).to(device)\n\u001b[32m     14\u001b[39m pages_and_chunks = text_chunks_and_embeddings_df.to_dict(orient=\u001b[33m'\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'float' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "text_chunks_and_embeddings_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "\n",
    "text_chunks_and_embeddings_df['embedding'] = text_chunks_and_embeddings_df['embedding'].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=' '))\n",
    "\n",
    "embeddings = torch.tensor(np.stack(text_chunks_and_embeddings_df['embedding'].tolist(), axis=0), dtype=torch.float32).to(device)\n",
    "\n",
    "pages_and_chunks = text_chunks_and_embeddings_df.to_dict(orient='records')\n",
    "\n",
    "text_chunks_and_embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4773d0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'М.Л.) Комментировать этот диалог достаточно просто. Здесь легко просматриваются приемы амортизации непосредственной и профилактической. Заслуживает разбора лишь'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embeddings_df['sentence_text'][2353]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd94fdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3245, 768])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d7d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path='all-mpnet-base-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de557346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Здоровые отношения между людьми способствуют их эмоциональному благополучию и личностному росту.\n",
      "[INFO] Time taken to compute dot product scores: 0.0002 seconds \n",
      " len = 3245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.8361, 0.8087, 0.8010, 0.7972, 0.7829], device='cuda:0'),\n",
       "indices=tensor([1312, 1120,  846, 2353,  711], device='cuda:0'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import perf_counter as timer\n",
    "\n",
    "query = 'Здоровые отношения между людьми способствуют их эмоциональному благополучию и личностному росту.'\n",
    "print(f'Query: {query}')\n",
    "\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True).to(device)\n",
    "\n",
    "cosine_scores = util.cos_sim(query_embedding, embeddings)[0]\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(f'[INFO] Time taken to compute dot product scores: {end_time - start_time:.4f} seconds \\n len = {len(embeddings)}')\n",
    "\n",
    "top_results_of_the_dot_product = torch.topk(dot_scores, k=5)\n",
    "top_results_of_the_dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7990ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Возможно, лучшей иллюстрацией опыта, который способен изменить темперамент в лучшую сторону, служат результаты проведенных Кейганом экспериментов с участием застенчивых детей.\n",
      "Теперь при обучении летчиков наряду с техническим мастерством особое внимание уделяется взаимодействию, открытой коммуникации,\n",
      "И такая бесстрастная манера рассуждать логически, по мнению Дамасио, составляла суть проблемы Эллиота: неспособность понять собственные чувства, возникающие по поводу разных обстоятельств, вносила ошибку в его рассуждения.\n",
      "М.Л.) Комментировать этот диалог достаточно просто. Здесь легко просматриваются приемы амортизации непосредственной и профилактической. Заслуживает разбора лишь\n",
      "Но они же способны легко сбить нас с пути истинного, что часто и происходит. Как представлялось Аристотелю, дело не в эмоциональности, а в уместности эмоций и их выражения. Вопрос в том, как сделать наши эмоции разумными, а цивилизованное поведение — нормой жизни общества.\n"
     ]
    }
   ],
   "source": [
    "for i in top_results_of_the_dot_product.indices.tolist():\n",
    "    print(text_chunks_and_embeddings_df['sentence_text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e944f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger embeddings shape: torch.Size([3245000, 768])\n",
      "[INFO] Time taken to compute dot product scores with larger embeddings: 0.0005 seconds \n",
      " len = 3245000\n"
     ]
    }
   ],
   "source": [
    "larger_embeddings = torch.randn(1000*embeddings.shape[0], 768).to(device)\n",
    "print(f\"Larger embeddings shape: {larger_embeddings.shape}\")\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(query_embedding, larger_embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(f'[INFO] Time taken to compute dot product scores with larger embeddings: {end_time - start_time:.4f} seconds \\n len = {len(larger_embeddings)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c20dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text: str, width: int=80):\n",
    "    wrapped_text = textwrap.fill(text, width=width)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf144e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Здоровые отношения между людьми способствуют их эмоциональному благополучию и личностному росту.\n",
      "\n",
      "Results:\n",
      "Score: 0.8361 | Text: Возможно, лучшей иллюстрацией опыта, который способен\n",
      "изменить темперамент в лучшую сторону, служат результаты проведенных Кейганом\n",
      "экспериментов с участием застенчивых детей.\n",
      "Score: 0.8087 | Text: Теперь при обучении летчиков наряду с техническим\n",
      "мастерством особое внимание уделяется взаимодействию, открытой коммуникации,\n",
      "Score: 0.8010 | Text: И такая бесстрастная манера рассуждать логически, по\n",
      "мнению Дамасио, составляла суть проблемы Эллиота: неспособность понять\n",
      "собственные чувства, возникающие по поводу разных обстоятельств, вносила ошибку\n",
      "в его рассуждения.\n",
      "Score: 0.7972 | Text: М.Л.) Комментировать этот диалог достаточно просто. Здесь\n",
      "легко просматриваются приемы амортизации непосредственной и профилактической.\n",
      "Заслуживает разбора лишь\n",
      "Score: 0.7829 | Text: Но они же способны легко сбить нас с пути истинного, что\n",
      "часто и происходит. Как представлялось Аристотелю, дело не в эмоциональности, а\n",
      "в уместности эмоций и их выражения. Вопрос в том, как сделать наши эмоции\n",
      "разумными, а цивилизованное поведение — нормой жизни общества.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Results:\")\n",
    "\n",
    "for score, idx in zip(top_results_of_the_dot_product[0], top_results_of_the_dot_product[1]):\n",
    "    print_wrapped(f\"Score: {score:.4f} | Text: {pages_and_chunks[idx]['sentence_text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4d6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7029c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aad04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999aa746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee8344d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
