{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed63bc32",
   "metadata": {},
   "source": [
    "# Создание простой RAG системы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a792f1",
   "metadata": {},
   "source": [
    "Я реализую простую RAG систему как чат с электронным психологом. То есть за данные берем известные книги по психологии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee980c7c",
   "metadata": {},
   "source": [
    "## Шаг 1: Препроцессинг данных и создание эмбедингов\n",
    "План:\n",
    "1. Импорт pdf файлов\n",
    "2. Препроцессинг текста для эмбедингов (разделение на чанки)\n",
    "3. Эмбендинг чанков текста с помощью эмбендинговой модели\n",
    "4. Сохранение эмбендингов в файл"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd82b27",
   "metadata": {},
   "source": [
    "## 1. Импорт pdf файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e79d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] File exists. Skipping Allana-Piza-YAzyk-telodvizhenij...\n",
      "[INFO] File exists. Skipping Eric-Berne-games-that-people-play...\n",
      "[INFO] File exists. Skipping Goleman-D.-Emotional-Intelligence.-Why-it-may-be-more-important-than-IQ...\n",
      "[INFO] File exists. Skipping Gurina-Koshenova-Rabota-psikhologa-s_detskoi...\n",
      "[INFO] File exists. Skipping Psihology-Aykido...\n",
      "[INFO] File exists. Skipping Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauchitsya-ubezhdat-y-dobivatsya-uspeha...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "pdf_path = 'psichology books/'\n",
    "books = ['Allana-Piza-YAzyk-telodvizhenij', 'Eric-Berne-games-that-people-play', 'Goleman-D.-Emotional-Intelligence.-Why-it-may-be-more-important-than-IQ', 'Gurina-Koshenova-Rabota-psikhologa-s_detskoi', 'Psihology-Aykido', 'Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauchitsya-ubezhdat-y-dobivatsya-uspeha']\n",
    "\n",
    "for book in books:\n",
    "    if os.path.exists(pdf_path + book + '.pdf'):\n",
    "        print(f'[INFO] File exists. Skipping {book}...')\n",
    "    else:\n",
    "        print(f'[INFO] {book} is not found')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbbd054",
   "metadata": {},
   "outputs": [],
   "source": [
    " #\\xa0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ce6d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285acfd746f343f1998cddfd946d66b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77da45603b734851b1d7c60c77b6eb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e02ae6d9b844a1ab0f0f475300778e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4506f45a2d44a0e9f056d47ec4210cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4d3456d28b4229add426389b75e312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9631ac54198947d3b7c4cfe545ae768f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1748"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def text_formatter(text : str) -> str:\n",
    "    \"\"\"Performs basic text formatting.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def open_and_read_pdf(file_path: str) -> list[str]:\n",
    "    doc = fitz.open(file_path)\n",
    "    pages_and_texts = []\n",
    "    for page_num, page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text(\"text\")\n",
    "        text = text_formatter(text=text)\n",
    "        if \"Goleman\" in file_path:\n",
    "            text = text.replace(\"\\xa0\", \" \")\n",
    "        pages_and_texts.append({\"book\": file_path[17:-4], \"page_num\": page_num, \"page_char_count\": len(text), \"page_word_count\": len(text.split()), \"page_token_count\": len(text)/4, \"text\": text})\n",
    "    return  pages_and_texts\n",
    "\n",
    "texts = []\n",
    "for book in books:\n",
    "    texts.extend(open_and_read_pdf(pdf_path + book + '.pdf'))\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac20557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences extracted: 26184\n"
     ]
    }
   ],
   "source": [
    "# Дополнительный препроцессинг текста\n",
    "\n",
    "import re\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy3  # pip install pymorphy3\n",
    "\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "def lemmatize(text: str) -> str:\n",
    "    return ' '.join(morph.parse(word)[0].normal_form for word in text.split())\n",
    "\n",
    "def advanced_text_formatter(text: str) -> str:\n",
    "    \"\"\"Enhanced text formatting beyond basic.\"\"\"\n",
    "    # Step 1: Remove hyphens from word breaks\n",
    "    text = re.sub(r'(\\\\w+)-\\\\s+(\\\\w+)', r'\\\\1\\\\2', text)\n",
    "    \n",
    "    # Step 2: Normalize multiple spaces\n",
    "    text = re.sub(r'\\\\s+', ' ', text)\n",
    "    \n",
    "    # Step 3: Remove specific annotations like footnotes\n",
    "    text = re.sub(r'—\\\\s*Примеч\\\\.\\\\s*пер\\\\.\\\\s*', '', text)\n",
    "    text = re.sub(r'\\\\(\\\\s*\\\\d+\\\\s*\\\\)\\\\.', '', text)\n",
    "    \n",
    "    # Lemmatize and lowercase\n",
    "    text = lemmatize(text.lower())  # Добавьте lowercase для унификации\n",
    "    \n",
    "    # Remove stops AFTER lemmatize (закомментировано: лучше для эмбеддингов)\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    \n",
    "    if len(text.strip()) == 0:  # Проверка на пустой текст\n",
    "        return \"\"\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Fallback sentence splitter if NLTK not available\n",
    "def custom_sent_tokenize(text: str) -> list[str]:\n",
    "    \"\"\"Custom regex-based sentence tokenizer for Russian text.\"\"\"\n",
    "    sentence_end = re.compile(r'(?<!\\\\w\\\\.\\\\w.)(?<![A-ZА-Я][a-zа-я]\\\\.)(?<=\\\\.|\\\\?|\\\\!|\\\\…)\\\\s')\n",
    "    sentences = sentence_end.split(text)\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "# Apply advanced formatting to existing texts\n",
    "for item in texts:\n",
    "    item['text'] = advanced_text_formatter(item['text'])\n",
    "\n",
    "# Now split into sentences\n",
    "sentences = []\n",
    "for item in texts:\n",
    "    if not item['text']:  # Пропуск пустых\n",
    "        continue\n",
    "    # Use NLTK if available\n",
    "    try:\n",
    "        page_sentences = sent_tokenize(item['text'], language='russian')\n",
    "    except:\n",
    "        page_sentences = custom_sent_tokenize(item['text'])\n",
    "    \n",
    "    for sent in page_sentences:\n",
    "        # Step 6: Trim leading/trailing punctuation if unnecessary\n",
    "        sent = re.sub(r'^[^\\\\w]+', '', sent)  # Remove leading non-word chars\n",
    "        sent = re.sub(r'[^\\\\w]+$', '', sent)  # Remove trailing non-word chars\n",
    "        \n",
    "        sentences.append({\n",
    "            \"book\": item['book'],\n",
    "            \"page_num\": item['page_num'],\n",
    "            \"sentence\": sent,\n",
    "            \"sent_char_count\": len(sent),\n",
    "            \"sent_word_count\": len(sent.split()),\n",
    "            \"sent_token_count\": len(sent) / 4\n",
    "        })\n",
    "\n",
    "print(f\"Total sentences extracted: {len(sentences)}\")\n",
    "\n",
    "# Optionally, save to file or further process\n",
    "import json\n",
    "with open('processed_sentences.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sentences, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a782c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'психика медицина 281 глава 11 психика медицина «кто научить всему, доктор?» ответ последовать незамедлительно: «страдание». альбер камю . чума непонятный тупой боль пах погнать больницу. осмотр выявить необычного, пока врач увидеть результат анали- мочи: обнаружить след крови. — хочу, лечь больница пройти кое- иссле- дования. проверить работа почек, сделать цитологию… — сказать деловой тоном. помню, говорить дальше. сознание, казалось, засты- ло слово «цитология». рак. остаться смутный воспоминание, объяснял, должный пройти диагностику. простейшее указания, прийтись просить несколько повторить. «цитология…» — ум желать расставаться это словом. оно вызвать чувство, сзади схватить горло грабить порог соб- ственный дома.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[700]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "126f2690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>1</td>\n",
       "      <td>1378</td>\n",
       "      <td>182</td>\n",
       "      <td>344.50</td>\n",
       "      <td>annotation книга аллан пиза «язык телодвижений...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>2</td>\n",
       "      <td>1021</td>\n",
       "      <td>138</td>\n",
       "      <td>255.25</td>\n",
       "      <td>различие пространственный зона горожанин жител...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>3</td>\n",
       "      <td>1052</td>\n",
       "      <td>142</td>\n",
       "      <td>263.00</td>\n",
       "      <td>жест скрещивание рук, усиленный сжатие палец к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>4</td>\n",
       "      <td>902</td>\n",
       "      <td>112</td>\n",
       "      <td>225.50</td>\n",
       "      <td>жесты, использовать мужчина ухаживание жест си...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              book  page_num  page_char_count  \\\n",
       "0  Allana-Piza-YAzyk-telodvizhenij         0                0   \n",
       "1  Allana-Piza-YAzyk-telodvizhenij         1             1378   \n",
       "2  Allana-Piza-YAzyk-telodvizhenij         2             1021   \n",
       "3  Allana-Piza-YAzyk-telodvizhenij         3             1052   \n",
       "4  Allana-Piza-YAzyk-telodvizhenij         4              902   \n",
       "\n",
       "   page_word_count  page_token_count  \\\n",
       "0                0              0.00   \n",
       "1              182            344.50   \n",
       "2              138            255.25   \n",
       "3              142            263.00   \n",
       "4              112            225.50   \n",
       "\n",
       "                                                text  \n",
       "0                                                     \n",
       "1  annotation книга аллан пиза «язык телодвижений...  \n",
       "2  различие пространственный зона горожанин жител...  \n",
       "3  жест скрещивание рук, усиленный сжатие палец к...  \n",
       "4  жесты, использовать мужчина ухаживание жест си...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(texts)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b187db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>187.05</td>\n",
       "      <td>1719.60</td>\n",
       "      <td>239.63</td>\n",
       "      <td>429.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>135.44</td>\n",
       "      <td>618.48</td>\n",
       "      <td>93.74</td>\n",
       "      <td>154.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.00</td>\n",
       "      <td>1514.25</td>\n",
       "      <td>211.00</td>\n",
       "      <td>378.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>161.00</td>\n",
       "      <td>1939.00</td>\n",
       "      <td>264.00</td>\n",
       "      <td>484.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>275.00</td>\n",
       "      <td>2102.00</td>\n",
       "      <td>288.00</td>\n",
       "      <td>525.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>544.00</td>\n",
       "      <td>3273.00</td>\n",
       "      <td>1386.00</td>\n",
       "      <td>818.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  page_char_count  page_word_count  page_token_count\n",
       "count   1748.00          1748.00          1748.00           1748.00\n",
       "mean     187.05          1719.60           239.63            429.90\n",
       "std      135.44           618.48            93.74            154.62\n",
       "min        0.00             0.00             0.00              0.00\n",
       "25%       74.00          1514.25           211.00            378.56\n",
       "50%      161.00          1939.00           264.00            484.75\n",
       "75%      275.00          2102.00           288.00            525.50\n",
       "max      544.00          3273.00          1386.00            818.25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63f00d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Это первое предложение., Это второе предложение!, А это третье предложение?]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.ru import Russian\n",
    "nlp = Russian()\n",
    "\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "doc = nlp('Это первое предложение. Это второе предложение! А это третье предложение?')\n",
    "assert len(list(doc.sents)) == 3\n",
    "\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc6f559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c6f8454063445cb7980a742ce3a8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1748 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(texts):\n",
    "    item['sentences'] = list(nlp(item['text']).sents)\n",
    "\n",
    "    item['sentences'] = [str(sent) for sent in item['sentences']]\n",
    "\n",
    "    item['page_sentence_count_spacy'] = len(item['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e20771b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book': 'Allana-Piza-YAzyk-telodvizhenij',\n",
       "  'page_num': 213,\n",
       "  'page_char_count': 0,\n",
       "  'page_word_count': 0,\n",
       "  'page_token_count': 0.0,\n",
       "  'text': '',\n",
       "  'sentences': [],\n",
       "  'page_sentence_count_spacy': 0}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d52a0caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>187.05</td>\n",
       "      <td>1719.60</td>\n",
       "      <td>239.63</td>\n",
       "      <td>429.90</td>\n",
       "      <td>15.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>135.44</td>\n",
       "      <td>618.48</td>\n",
       "      <td>93.74</td>\n",
       "      <td>154.62</td>\n",
       "      <td>11.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.00</td>\n",
       "      <td>1514.25</td>\n",
       "      <td>211.00</td>\n",
       "      <td>378.56</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>161.00</td>\n",
       "      <td>1939.00</td>\n",
       "      <td>264.00</td>\n",
       "      <td>484.75</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>275.00</td>\n",
       "      <td>2102.00</td>\n",
       "      <td>288.00</td>\n",
       "      <td>525.50</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>544.00</td>\n",
       "      <td>3273.00</td>\n",
       "      <td>1386.00</td>\n",
       "      <td>818.25</td>\n",
       "      <td>111.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  page_char_count  page_word_count  page_token_count  \\\n",
       "count   1748.00          1748.00          1748.00           1748.00   \n",
       "mean     187.05          1719.60           239.63            429.90   \n",
       "std      135.44           618.48            93.74            154.62   \n",
       "min        0.00             0.00             0.00              0.00   \n",
       "25%       74.00          1514.25           211.00            378.56   \n",
       "50%      161.00          1939.00           264.00            484.75   \n",
       "75%      275.00          2102.00           288.00            525.50   \n",
       "max      544.00          3273.00          1386.00            818.25   \n",
       "\n",
       "       page_sentence_count_spacy  \n",
       "count                    1748.00  \n",
       "mean                       15.76  \n",
       "std                        11.12  \n",
       "min                         0.00  \n",
       "25%                        10.00  \n",
       "50%                        14.00  \n",
       "75%                        18.00  \n",
       "max                       111.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(texts)\n",
    "data.describe().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d76a414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4],\n",
       " [5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14],\n",
       " [15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunking with spacy sentences (1 chunk = ?10? sentences). \n",
    "\n",
    "num_sentences_per_chunk = 5 # пробовала 10, 7\n",
    "\n",
    "def split_list(input_list: list[str], slice_size: int=num_sentences_per_chunk) -> list[list[str]]:\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "test_list = list(range(25))\n",
    "split_list(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6db939a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d53a80b45c42e491ec5890e15978db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1748 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68de1af344f74afc80c7dc0b142ad28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5512"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "all_sentences = []\n",
    "for item in tqdm(texts):\n",
    "    for sent in item['sentences']:\n",
    "        all_sentences.append({\n",
    "            \"sentence\": str(sent),\n",
    "            \"book\": item['book'],\n",
    "            \"page_num\": item['page_num']\n",
    "        })\n",
    "\n",
    "\n",
    "sentence_chunks = split_list(all_sentences, slice_size=num_sentences_per_chunk)\n",
    "\n",
    "\n",
    "pages_and_chunks = []\n",
    "for chunk in tqdm(sentence_chunks):\n",
    "    chunk_dict = {}\n",
    "    chunk_dict['book'] = chunk[0]['book']\n",
    "    chunk_dict['page_num'] = chunk[0]['page_num']\n",
    "    \n",
    "    # Join the sentences in the chunk\n",
    "    joined_sentence_chunk = \" \".join([item['sentence'] for item in chunk]).replace(\"  \", \" \").strip()\n",
    "    joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk)\n",
    "    chunk_dict['sentence_text'] = joined_sentence_chunk\n",
    "    \n",
    "    # Recalculate stats for the new chunk\n",
    "    chunk_dict['chunk_char_count'] = len(joined_sentence_chunk)\n",
    "    chunk_dict['chunk_word_count'] = len(joined_sentence_chunk.split(\" \"))\n",
    "    chunk_dict['chunk_token_count'] = len(joined_sentence_chunk) / 4\n",
    "    \n",
    "    pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f1748da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book': 'Gurina-Koshenova-Rabota-psikhologa-s_detskoi',\n",
       "  'page_num': 40,\n",
       "  'page_char_count': 1906,\n",
       "  'page_word_count': 255,\n",
       "  'page_token_count': 476.5,\n",
       "  'text': '41 ектом (событием) общий схемой. восприятие рассматривает- ся процесс генерализация объект конкретизация схема [42]. мнение д. нормана, схема – это некий пакет информации, определённый комплекс знаний, касаться какой-либо области. схема включать значительный сведение соответствующий понятиях, число типичный особенность обозначать объектов. так, схема «животное» констатирует, это организм голова, схема «млекопитающее» – организм че- тырь конечность т. д. [47]. д. румельхарт д. норман схема понимать единица организовать информации, взаимосвязанный структура знания, который принимать участие понимание входной информация управлять процесс обработки. этап, называть «структурирование знания», включать формирование новый схема основа существующий путём видоизменение последний вли- яние новый опыт [42]. дж. брунер формулировать конструктивистский теория познания, указывать селективный функция схема познании. теория речь идти том, новый опыт «ложится» существующий категории, который придавать иной значение. категория определённый образ организовать поступать информацию, да- вая возможность человек выдвигать гипотеза отношение воспри- нимаять объект [42]. безусловно, схема формироваться процесс онтогенеза, рожда- ясь первичный наблюдение момент наш обработка посто- янно усложняться мера развитие человека. наиболее полный кон- цепция развитие когнитивный схема сформулировать ж. пиажа (1969), речь дать теория идти далее. 1.2.2. представление психический травма разрушение базовый схема убеждение наиболее развернуть структурировать теория генетиче- ский развитие когнитивный схема предложить швейцарский учёный ж. пиажа (1969). указывать ведущий значение схема когнитив-',\n",
       "  'sentences': ['41 ектом (событием) общий схемой.',\n",
       "   'восприятие рассматривает- ся процесс генерализация объект конкретизация схема [42].',\n",
       "   'мнение д. нормана, схема – это некий пакет информации, определённый комплекс знаний, касаться какой-либо области.',\n",
       "   'схема включать значительный сведение соответствующий понятиях, число типичный особенность обозначать объектов.',\n",
       "   'так, схема «животное» констатирует, это организм голова, схема «млекопитающее» – организм че- тырь конечность т.',\n",
       "   'д. [47].',\n",
       "   'д. румельхарт д. норман схема понимать единица организовать информации, взаимосвязанный структура знания, который принимать участие понимание входной информация управлять процесс обработки.',\n",
       "   'этап, называть «структурирование знания», включать формирование новый схема основа существующий путём видоизменение последний вли- яние новый опыт [42].',\n",
       "   'дж.',\n",
       "   'брунер формулировать конструктивистский теория познания, указывать селективный функция схема познании.',\n",
       "   'теория речь идти том, новый опыт «ложится» существующий категории, который придавать иной значение.',\n",
       "   'категория определённый образ организовать поступать информацию, да- вая возможность человек выдвигать гипотеза отношение воспри- нимаять объект [42].',\n",
       "   'безусловно, схема формироваться процесс онтогенеза, рожда- ясь первичный наблюдение момент наш обработка посто- янно усложняться мера развитие человека.',\n",
       "   'наиболее полный кон- цепция развитие когнитивный схема сформулировать ж.',\n",
       "   'пиажа (1969), речь дать теория идти далее.',\n",
       "   '1.2.2.',\n",
       "   'представление психический травма разрушение базовый схема убеждение наиболее развернуть структурировать теория генетиче- ский развитие когнитивный схема предложить швейцарский учёный ж.',\n",
       "   'пиажа (1969).',\n",
       "   'указывать ведущий значение схема когнитив-'],\n",
       "  'page_sentence_count_spacy': 19}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cf0f228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>187.05</td>\n",
       "      <td>1719.60</td>\n",
       "      <td>239.63</td>\n",
       "      <td>429.90</td>\n",
       "      <td>15.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>135.44</td>\n",
       "      <td>618.48</td>\n",
       "      <td>93.74</td>\n",
       "      <td>154.62</td>\n",
       "      <td>11.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.00</td>\n",
       "      <td>1514.25</td>\n",
       "      <td>211.00</td>\n",
       "      <td>378.56</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>161.00</td>\n",
       "      <td>1939.00</td>\n",
       "      <td>264.00</td>\n",
       "      <td>484.75</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>275.00</td>\n",
       "      <td>2102.00</td>\n",
       "      <td>288.00</td>\n",
       "      <td>525.50</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>544.00</td>\n",
       "      <td>3273.00</td>\n",
       "      <td>1386.00</td>\n",
       "      <td>818.25</td>\n",
       "      <td>111.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  page_char_count  page_word_count  page_token_count  \\\n",
       "count   1748.00          1748.00          1748.00           1748.00   \n",
       "mean     187.05          1719.60           239.63            429.90   \n",
       "std      135.44           618.48            93.74            154.62   \n",
       "min        0.00             0.00             0.00              0.00   \n",
       "25%       74.00          1514.25           211.00            378.56   \n",
       "50%      161.00          1939.00           264.00            484.75   \n",
       "75%      275.00          2102.00           288.00            525.50   \n",
       "max      544.00          3273.00          1386.00            818.25   \n",
       "\n",
       "       page_sentence_count_spacy  \n",
       "count                    1748.00  \n",
       "mean                       15.76  \n",
       "std                        11.12  \n",
       "min                         0.00  \n",
       "25%                        10.00  \n",
       "50%                        14.00  \n",
       "75%                        18.00  \n",
       "max                       111.00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd9733da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0677a42400a4760b434dc4586d7d8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1748 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db7b7fe87284a2b864564b9f115d488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1748 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3596"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "num_sentences_per_chunk = 10\n",
    "def split_list(input_list: list, slice_size: int = num_sentences_per_chunk) -> list[list]:\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "for item in tqdm(texts):\n",
    "    if 'sentences' in item:\n",
    "        item['sentence_chunks'] = split_list(item['sentences'])\n",
    "        item['num_chunks'] = len(item['sentence_chunks'])\n",
    "\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(texts):\n",
    "    if 'sentence_chunks' in item:\n",
    "        for sentence_chunk in item['sentence_chunks']:\n",
    "            chunk_dict = {}\n",
    "            chunk_dict['book'] = item['book']\n",
    "            chunk_dict['page_num'] = item['page_num']\n",
    "            joined_sentence_chunk = ' '.join(map(str, sentence_chunk)).replace(\"  \", \" \").strip()\n",
    "            joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk)\n",
    "            chunk_dict['sentence_text'] = joined_sentence_chunk\n",
    "            \n",
    "            chunk_dict['chunk_char_count'] = len(joined_sentence_chunk)\n",
    "            chunk_dict['chunk_word_count'] = len(joined_sentence_chunk.split(\" \"))\n",
    "            chunk_dict['chunk_token_count'] = len(joined_sentence_chunk)/4\n",
    "\n",
    "            pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67ec6ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book': 'Allana-Piza-YAzyk-telodvizhenij',\n",
       "  'page_num': 178,\n",
       "  'sentence_text': 'курение процесс курение внешний проявление внутренний дисба-ланс конфликт внутри человека, иметь слишком мало общий привязанность поглощение никотина. это способов, который пользоваться современный человек условие повышенный стресса, ослабление напряжение свой нервов, который накапли-ваться процесс социальный деловой контактов. например, большинство человек испытывать внутренний напряжение, сидя приёмный дантист ожидание удаление зуба. курильщик сгладить свой напряжение помощь курения, некурящий проделывать ритуальный жесты. отряхивать одежду, грызть ногти, стучать палец ногами, поправлять запонки, почёсывать затылок, снимать одевать кольцо пальца, вертеть рука галстук демонстрировать множество жестов, который говорить том, человек нервничает, требоваться поддержка.',\n",
       "  'chunk_char_count': 776,\n",
       "  'chunk_word_count': 86,\n",
       "  'chunk_token_count': 194.0}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16226e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "      <td>1748.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>187.05</td>\n",
       "      <td>1719.60</td>\n",
       "      <td>239.63</td>\n",
       "      <td>429.90</td>\n",
       "      <td>15.76</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>135.44</td>\n",
       "      <td>618.48</td>\n",
       "      <td>93.74</td>\n",
       "      <td>154.62</td>\n",
       "      <td>11.12</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.00</td>\n",
       "      <td>1514.25</td>\n",
       "      <td>211.00</td>\n",
       "      <td>378.56</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>161.00</td>\n",
       "      <td>1939.00</td>\n",
       "      <td>264.00</td>\n",
       "      <td>484.75</td>\n",
       "      <td>14.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>275.00</td>\n",
       "      <td>2102.00</td>\n",
       "      <td>288.00</td>\n",
       "      <td>525.50</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>544.00</td>\n",
       "      <td>3273.00</td>\n",
       "      <td>1386.00</td>\n",
       "      <td>818.25</td>\n",
       "      <td>111.00</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  page_char_count  page_word_count  page_token_count  \\\n",
       "count   1748.00          1748.00          1748.00           1748.00   \n",
       "mean     187.05          1719.60           239.63            429.90   \n",
       "std      135.44           618.48            93.74            154.62   \n",
       "min        0.00             0.00             0.00              0.00   \n",
       "25%       74.00          1514.25           211.00            378.56   \n",
       "50%      161.00          1939.00           264.00            484.75   \n",
       "75%      275.00          2102.00           288.00            525.50   \n",
       "max      544.00          3273.00          1386.00            818.25   \n",
       "\n",
       "       page_sentence_count_spacy  num_chunks  \n",
       "count                    1748.00     1748.00  \n",
       "mean                       15.76        2.06  \n",
       "std                        11.12        1.13  \n",
       "min                         0.00        0.00  \n",
       "25%                        10.00        1.00  \n",
       "50%                        14.00        2.00  \n",
       "75%                        18.00        2.00  \n",
       "max                       111.00       12.00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8565c0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_num</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3596.00</td>\n",
       "      <td>3596.00</td>\n",
       "      <td>3596.00</td>\n",
       "      <td>3596.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>194.82</td>\n",
       "      <td>717.56</td>\n",
       "      <td>86.49</td>\n",
       "      <td>179.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>143.75</td>\n",
       "      <td>433.65</td>\n",
       "      <td>50.45</td>\n",
       "      <td>108.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>72.00</td>\n",
       "      <td>359.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>89.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>163.00</td>\n",
       "      <td>660.50</td>\n",
       "      <td>81.00</td>\n",
       "      <td>165.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>292.00</td>\n",
       "      <td>1042.25</td>\n",
       "      <td>123.00</td>\n",
       "      <td>260.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>543.00</td>\n",
       "      <td>2042.00</td>\n",
       "      <td>276.00</td>\n",
       "      <td>510.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_num  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count   3596.00           3596.00           3596.00            3596.00\n",
       "mean     194.82            717.56             86.49             179.39\n",
       "std      143.75            433.65             50.45             108.41\n",
       "min        0.00              2.00              1.00               0.50\n",
       "25%       72.00            359.00             46.00              89.75\n",
       "50%      163.00            660.50             81.00             165.12\n",
       "75%      292.00           1042.25            123.00             260.56\n",
       "max      543.00           2042.00            276.00             510.50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41c213da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 26.25 | Text: под- тверждение стать результат исследования, провести начальный школа использование нейропсихологический\n",
      "Chunk token count: 18.5 | Text: зависимость обстоятельство мочь присоединяться эмоциональный поведенческий\n",
      "Chunk token count: 15.0 | Text: искусство общение 223 часть iii эмоциональный разум действие\n",
      "Chunk token count: 15.25 | Text: глава угол поставить основный способность, который невозможно\n",
      "Chunk token count: 14.5 | Text: темперамент приговор 383 часть v эмоциональный грамотность\n"
     ]
    }
   ],
   "source": [
    "min_token_length = 30\n",
    "for row in df[df['chunk_token_count'] <= min_token_length].sample(5).iterrows():\n",
    "\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3908627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book': 'Allana-Piza-YAzyk-telodvizhenij',\n",
       "  'page_num': 17,\n",
       "  'sentence_text': 'конгруэнтность — совпадение слово жест собеседник человека, показать рис. 4, попросить выразить свой мнение относительно того, сказали, ответил, согласен, невербальный сигнал конгруэнтными, т.е. соответ-ствовали словесный высказываниям. скажет, очень нравиться все, говорите, лгать, слово жест конгруэнтными. исследование доказывают, невербальный сигнал нести 5 большой информации, вербальные, случае, сигнал — конгруэнтны, человек полагаться невербальный информацию, предпочитать словесной. часто наблюдать, какой-нибудь политик стоить трибуне, крепко скрестить рука грудь ( защитный поза ) опустить подбородок ( критический враждебный поза), говорить аудитория том, восприимчивый дружелюбно относиться идея молодежи. мочь попытаться убедить аудитория свой теплом, гуманный отношении, делать быстрые, резкий удар трибуне. зигмунд фрейд однажды заметил, пациентка словесно убеждать том, счастливый браке, бессознательно снимать палец надевать обручальный кольцо. фрейд понять значение это непроизвольный жест удивился, стать обозначаться семейный проблема пациентки.',\n",
       "  'chunk_char_count': 1066,\n",
       "  'chunk_word_count': 123,\n",
       "  'chunk_token_count': 266.5},\n",
       " {'book': 'Allana-Piza-YAzyk-telodvizhenij',\n",
       "  'page_num': 18,\n",
       "  'sentence_text': 'ключ правильный интерпретация жест являться учитывание весь совокупность жест конгруэнтность вербальный невербальный сигналов.',\n",
       "  'chunk_char_count': 126,\n",
       "  'chunk_word_count': 13,\n",
       "  'chunk_token_count': 31.5},\n",
       " {'book': 'Allana-Piza-YAzyk-telodvizhenij',\n",
       "  'page_num': 19,\n",
       "  'sentence_text': 'значение контекст толкование жест кроме учёт совокупность жест соответствие слово телодвижениями, правильный интерпретация жест необходимо учитывать контекст, который жить жесты. вы, например, холодный зимний день увидеть автобусный остановка человека, сидеть скрестить ногами, крепко скрестить грудь рука опустить вниз головой, это скорее весь означать, замерз, вовсе критический отношение чему-либо. однако, человек точно положение сидеть напротив стол переговоры заключение сделки, жест совершенно определённо следовать трактовать иметь негативный оборонительный отношение сложиться ситуации. книга всё жест рассматриваться учёт окружающий ситуации, и, возможности, рассмотреться совокуп-ность жест контексте.',\n",
       "  'chunk_char_count': 712,\n",
       "  'chunk_word_count': 82,\n",
       "  'chunk_token_count': 178.0},\n",
       " {'book': 'Allana-Piza-YAzyk-telodvizhenij',\n",
       "  'page_num': 20,\n",
       "  'sentence_text': 'факторы, оказывать влияние интерпретация жест человек слабый рукопожатие, сделать вывод слабость характера, глава особенность рукопожатие исследовать причины, объяснять это утверждение. человек артрит сустав руки, использовать слабый рукопожатие, предохранить рука боли. поэтому художники, музыканты, хирург человек деликатный профессий, требоваться чуткий пальцы, обычно предпочитать обмениваться рукопожатиями, вынудить это делать, пользоваться щадить рукопожатием. люди, носить плохо сидеть тесный одежду, сковать свой движениях, это оказывать влияние выразительность язык тела. это достаточно редкий случаи, важно иметь виду, понять, психологический влияние иметь вещь бодить лэнгвидж.',\n",
       "  'chunk_char_count': 689,\n",
       "  'chunk_word_count': 79,\n",
       "  'chunk_token_count': 172.25},\n",
       " {'book': 'Allana-Piza-YAzyk-telodvizhenij',\n",
       "  'page_num': 21,\n",
       "  'sentence_text': 'положение общество богатство жестикуляция научный исследование область лингвистика показали, существовать прямой зависимость социальный статусом, власть престиж человек словарный запасом. словами, выше социальный профессиональный положение человека, хороший способность общаться уровень слово фраз. исследование область невербалики выявить зависимость красноречивость человек степень жестикуляции, использовать человек передача смысл свой сообщений. это означает, существовать прямой зависимость социальный положение человека, престиж количество жест телодвижений, который пользуется. человек, находиться вершина соци-альна лестница профессиональный карьеры, мочь пользоваться богатство свой словарный запас процесс коммуникации, время менее образовать менее профессиональный человек частый полагаться жесты, слово процесс общения. книга большинство пример описывать поведение человек среднее сословия, общий правило заключаться том, выше социально-экономический положение человека, менее развить жестикуляция бедный телодвижения. быстрота некоторый жест очевидность глаз зависеть возраст человека. например, 5-летний ребёнок сказать неправда свой родителям, сразу это прикрыть оба рука рот (рис. 5). жест «прикрывание рот рукой» подсказать родитель том, ребёнок солгал, протяжение весь свой жизнь человек использовать жест, лжет, обычно меняться скорость совершение это жеста.',\n",
       "  'chunk_char_count': 1377,\n",
       "  'chunk_word_count': 154,\n",
       "  'chunk_token_count': 344.25}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df['chunk_token_count'] > min_token_length].to_dict(orient='records')\n",
    "pages_and_chunks_over_min_token_len[20:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89efb2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book': 'Eric-Berne-games-that-people-play',\n",
       "  'page_num': 139,\n",
       "  'sentence_text': 'обра- зом выигрывать любой случае. блэк делает, это чувство беспомощности, что-нибудь делает, раздражения. поэтому человек склонный разыгрывать игра “а почему не. . . да, но. . . ”, доставлять удовле- творение мягкий форме. лёгкий решение видно, искать, пока хороший понять психодинамика игры. 7. деревянный нога наиболее драматический форма “деревянный ноги” — “ссылка ненормальность”. язык анализ взаимодействие это пере- водиться так: “чего хотеть человек расстроенны- ми эмоциями, меня, — мочь удержаться убий- ства!” это ожидаться ответ суда: “конечно, нет: мочь требовать этого!” “',\n",
       "  'chunk_char_count': 587,\n",
       "  'chunk_word_count': 82,\n",
       "  'chunk_token_count': 146.75}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks_over_min_token_len, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536437e",
   "metadata": {},
   "source": [
    "## Эмбендинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee93fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Delta-Game\\first_rag\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Delta-Game\\first_rag\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Своевременное управление своими эмоциями помогает человеку лучше адаптироваться в обществе и достигать успехов в различных сферах жизни.\n",
      "Embedding: [ 0.09367365  0.06438734  0.15397337  0.27672583 -0.28899655]\n",
      "\n",
      "Sentence: Эмоциональный интеллект включает в себя способность распознавать, понимать и управлять своими эмоциями, а также эмоциями других людей.\n",
      "Embedding: [-0.18342024 -0.00970362  0.11679667  0.56002    -0.312298  ]\n",
      "\n",
      "Sentence: Мне нравятся лошади\n",
      "Embedding: [ 0.09567402  0.13053127  0.00370111  0.27585265 -0.23311627]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "model_id =  'Geotrend/LaBSE-en-ru-v2'#hugging face model\n",
    "hf_token = \"get your token in http://hf.co/settings/tokens\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path=model_id, device='cpu')\n",
    "\n",
    "sentences = [\"Своевременное управление своими эмоциями помогает человеку лучше адаптироваться в обществе и достигать успехов в различных сферах жизни.\", \n",
    "             \"Эмоциональный интеллект включает в себя способность распознавать, понимать и управлять своими эмоциями, а также эмоциями других людей.\",\n",
    "             \"Мне нравятся лошади\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "embeddings_dictionary = dict(zip(sentences, embeddings))\n",
    "\n",
    "for sentence, embedding in embeddings_dictionary.items():\n",
    "    print(f'Sentence: {sentence}\\nEmbedding: {embedding[:5]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad5ce34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63f205",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "embedding_model.to('cpu')\n",
    "\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item['embedding'] = embedding_model.encode(item['sentence_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fd2032e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6173c451cc4f18affeb92502162646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 44.6 s\n",
      "Wall time: 42.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embedding_model.to('cuda')\n",
    "\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item['embedding'] = embedding_model.encode(item['sentence_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11f9c7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'внешний общественное. приводиться ключевой вы- ражение, применять аналогичный игра развлечении, разыг- рывать менее интимный обстановке. ( 5). биологическое. делаться попытка охарактеризовать вид поглаживания, ко- торой игра доставлять участникам. ( 6). экзистенциальное. указываться позиция, который игра разыгрываться типичный случаях. родственный игры: приводиться название дополнитель- ных, сходный противоположный (антитетических) игр. точный понимание игра мочь достигнуть лишь услови- яха психотерапии.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "embedding_model.to('cuda')\n",
    "\n",
    "text_chunks = [item[\"sentence_text\"] for item in pages_and_chunks_over_min_token_len]\n",
    "text_chunks[419]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01fddf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3371"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4297c620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.25 s\n",
      "Wall time: 3.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0397, -0.2058, -0.1221,  ...,  0.1773, -0.1527, -0.0165],\n",
       "        [ 0.0901,  0.0057,  0.1217,  ...,  0.2975, -0.1015,  0.2282],\n",
       "        [-0.0460,  0.0458,  0.1394,  ...,  0.1055, -0.0223,  0.2804],\n",
       "        ...,\n",
       "        [-0.0650,  0.0390, -0.2216,  ...,  0.2135, -0.0566,  0.1209],\n",
       "        [-0.0245,  0.0519, -0.1911,  ...,  0.1515, -0.0351,  0.1642],\n",
       "        [-0.0024, -0.1104, -0.3956,  ..., -0.1087, -0.2172,  0.2494]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text_chunk_embeddings = embedding_model.encode(text_chunks, batch_size=32, convert_to_tensor=True)\n",
    "\n",
    "text_chunk_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f5d146",
   "metadata": {},
   "source": [
    "## Сохранение эмбеддингов в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41ce7d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = 'text_chunks_and_embeddings_df.csv'\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96edafc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>page_num</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>1</td>\n",
       "      <td>annotation книга аллан пиза «язык телодвижений...</td>\n",
       "      <td>1181</td>\n",
       "      <td>134</td>\n",
       "      <td>295.25</td>\n",
       "      <td>[ 3.96876633e-02 -2.05777466e-01 -1.22056380e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>2</td>\n",
       "      <td>различие пространственный зона горожанин жител...</td>\n",
       "      <td>943</td>\n",
       "      <td>115</td>\n",
       "      <td>235.75</td>\n",
       "      <td>[ 9.01253074e-02  5.71551407e-03  1.21663198e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>3</td>\n",
       "      <td>жест скрещивание рук, усиленный сжатие палец к...</td>\n",
       "      <td>961</td>\n",
       "      <td>121</td>\n",
       "      <td>240.25</td>\n",
       "      <td>[-0.04603301  0.04575719  0.13937409 -0.031644...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>4</td>\n",
       "      <td>жесты, использовать мужчина ухаживание жест си...</td>\n",
       "      <td>818</td>\n",
       "      <td>99</td>\n",
       "      <td>204.50</td>\n",
       "      <td>[-0.02531953  0.17106412 -0.06040524  0.074408...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>5</td>\n",
       "      <td>ступень нога выражать заинтересованность распо...</td>\n",
       "      <td>704</td>\n",
       "      <td>89</td>\n",
       "      <td>176.00</td>\n",
       "      <td>[ 2.25336701e-01  1.51010826e-01 -4.16030847e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              book  page_num  \\\n",
       "0  Allana-Piza-YAzyk-telodvizhenij         1   \n",
       "1  Allana-Piza-YAzyk-telodvizhenij         2   \n",
       "2  Allana-Piza-YAzyk-telodvizhenij         3   \n",
       "3  Allana-Piza-YAzyk-telodvizhenij         4   \n",
       "4  Allana-Piza-YAzyk-telodvizhenij         5   \n",
       "\n",
       "                                       sentence_text  chunk_char_count  \\\n",
       "0  annotation книга аллан пиза «язык телодвижений...              1181   \n",
       "1  различие пространственный зона горожанин жител...               943   \n",
       "2  жест скрещивание рук, усиленный сжатие палец к...               961   \n",
       "3  жесты, использовать мужчина ухаживание жест си...               818   \n",
       "4  ступень нога выражать заинтересованность распо...               704   \n",
       "\n",
       "   chunk_word_count  chunk_token_count  \\\n",
       "0               134             295.25   \n",
       "1               115             235.75   \n",
       "2               121             240.25   \n",
       "3                99             204.50   \n",
       "4                89             176.00   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 3.96876633e-02 -2.05777466e-01 -1.22056380e-...  \n",
       "1  [ 9.01253074e-02  5.71551407e-03  1.21663198e-...  \n",
       "2  [-0.04603301  0.04575719  0.13937409 -0.031644...  \n",
       "3  [-0.02531953  0.17106412 -0.06040524  0.074408...  \n",
       "4  [ 2.25336701e-01  1.51010826e-01 -4.16030847e-...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df_save_path = 'text_chunks_and_embeddings_df.csv'\n",
    "text_chunks_and_embeddings_df = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57d15b6",
   "metadata": {},
   "source": [
    "Если бы у меня была действительно большая база данных эмбэндингов (100K - 1M) то тогда бы использовала векторную базу данных qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2580fbb",
   "metadata": {},
   "source": [
    "# Поиск и ответы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b346d055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>page_num</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>1</td>\n",
       "      <td>annotation книга аллан пиза «язык телодвижений...</td>\n",
       "      <td>1181</td>\n",
       "      <td>134</td>\n",
       "      <td>295.25</td>\n",
       "      <td>[0.0396876633, -0.205777466, -0.12205638, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>2</td>\n",
       "      <td>различие пространственный зона горожанин жител...</td>\n",
       "      <td>943</td>\n",
       "      <td>115</td>\n",
       "      <td>235.75</td>\n",
       "      <td>[0.0901253074, 0.00571551407, 0.121663198, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>3</td>\n",
       "      <td>жест скрещивание рук, усиленный сжатие палец к...</td>\n",
       "      <td>961</td>\n",
       "      <td>121</td>\n",
       "      <td>240.25</td>\n",
       "      <td>[-0.04603301, 0.04575719, 0.13937409, -0.03164...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>4</td>\n",
       "      <td>жесты, использовать мужчина ухаживание жест си...</td>\n",
       "      <td>818</td>\n",
       "      <td>99</td>\n",
       "      <td>204.50</td>\n",
       "      <td>[-0.02531953, 0.17106412, -0.06040524, 0.07440...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allana-Piza-YAzyk-telodvizhenij</td>\n",
       "      <td>5</td>\n",
       "      <td>ступень нога выражать заинтересованность распо...</td>\n",
       "      <td>704</td>\n",
       "      <td>89</td>\n",
       "      <td>176.00</td>\n",
       "      <td>[0.225336701, 0.151010826, -0.0416030847, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauc...</td>\n",
       "      <td>404</td>\n",
       "      <td>новый издание — почему оно актуально вас? разм...</td>\n",
       "      <td>319</td>\n",
       "      <td>39</td>\n",
       "      <td>79.75</td>\n",
       "      <td>[-0.117484666, 0.0297225341, -0.0382157266, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauc...</td>\n",
       "      <td>405</td>\n",
       "      <td>убийство вирджиния северный иллинойсе). 2. доп...</td>\n",
       "      <td>852</td>\n",
       "      <td>94</td>\n",
       "      <td>213.00</td>\n",
       "      <td>[-0.02763486, -0.11024814, -0.05699018, -0.105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3368</th>\n",
       "      <td>Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauc...</td>\n",
       "      <td>405</td>\n",
       "      <td>удвоиться количество отчёт читателей, рассказ ...</td>\n",
       "      <td>555</td>\n",
       "      <td>63</td>\n",
       "      <td>138.75</td>\n",
       "      <td>[-0.0649724379, 0.039032992, -0.221619144, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauc...</td>\n",
       "      <td>406</td>\n",
       "      <td>деятельность особенность заказчиков, дать возм...</td>\n",
       "      <td>1003</td>\n",
       "      <td>114</td>\n",
       "      <td>250.75</td>\n",
       "      <td>[-0.0244564228, 0.0519208908, -0.191072792, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauc...</td>\n",
       "      <td>406</td>\n",
       "      <td>думаю, прочитать ее, биться голова стена выбра...</td>\n",
       "      <td>284</td>\n",
       "      <td>35</td>\n",
       "      <td>71.00</td>\n",
       "      <td>[-0.00236183, -0.11041542, -0.39558873, 0.0244...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3371 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   book  page_num  \\\n",
       "0                       Allana-Piza-YAzyk-telodvizhenij         1   \n",
       "1                       Allana-Piza-YAzyk-telodvizhenij         2   \n",
       "2                       Allana-Piza-YAzyk-telodvizhenij         3   \n",
       "3                       Allana-Piza-YAzyk-telodvizhenij         4   \n",
       "4                       Allana-Piza-YAzyk-telodvizhenij         5   \n",
       "...                                                 ...       ...   \n",
       "3366  Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauc...       404   \n",
       "3367  Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauc...       405   \n",
       "3368  Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauc...       405   \n",
       "3369  Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauc...       406   \n",
       "3370  Robert-Chaldyny_Psyhologyya-vliyaniya_Kak-nauc...       406   \n",
       "\n",
       "                                          sentence_text  chunk_char_count  \\\n",
       "0     annotation книга аллан пиза «язык телодвижений...              1181   \n",
       "1     различие пространственный зона горожанин жител...               943   \n",
       "2     жест скрещивание рук, усиленный сжатие палец к...               961   \n",
       "3     жесты, использовать мужчина ухаживание жест си...               818   \n",
       "4     ступень нога выражать заинтересованность распо...               704   \n",
       "...                                                 ...               ...   \n",
       "3366  новый издание — почему оно актуально вас? разм...               319   \n",
       "3367  убийство вирджиния северный иллинойсе). 2. доп...               852   \n",
       "3368  удвоиться количество отчёт читателей, рассказ ...               555   \n",
       "3369  деятельность особенность заказчиков, дать возм...              1003   \n",
       "3370  думаю, прочитать ее, биться голова стена выбра...               284   \n",
       "\n",
       "      chunk_word_count  chunk_token_count  \\\n",
       "0                  134             295.25   \n",
       "1                  115             235.75   \n",
       "2                  121             240.25   \n",
       "3                   99             204.50   \n",
       "4                   89             176.00   \n",
       "...                ...                ...   \n",
       "3366                39              79.75   \n",
       "3367                94             213.00   \n",
       "3368                63             138.75   \n",
       "3369               114             250.75   \n",
       "3370                35              71.00   \n",
       "\n",
       "                                              embedding  \n",
       "0     [0.0396876633, -0.205777466, -0.12205638, -0.0...  \n",
       "1     [0.0901253074, 0.00571551407, 0.121663198, -0....  \n",
       "2     [-0.04603301, 0.04575719, 0.13937409, -0.03164...  \n",
       "3     [-0.02531953, 0.17106412, -0.06040524, 0.07440...  \n",
       "4     [0.225336701, 0.151010826, -0.0416030847, -0.0...  \n",
       "...                                                 ...  \n",
       "3366  [-0.117484666, 0.0297225341, -0.0382157266, 0....  \n",
       "3367  [-0.02763486, -0.11024814, -0.05699018, -0.105...  \n",
       "3368  [-0.0649724379, 0.039032992, -0.221619144, 0.1...  \n",
       "3369  [-0.0244564228, 0.0519208908, -0.191072792, 0....  \n",
       "3370  [-0.00236183, -0.11041542, -0.39558873, 0.0244...  \n",
       "\n",
       "[3371 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "text_chunks_and_embeddings_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "\n",
    "text_chunks_and_embeddings_df['embedding'] = text_chunks_and_embeddings_df['embedding'].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=' '))\n",
    "\n",
    "embeddings = torch.tensor(np.stack(text_chunks_and_embeddings_df['embedding'].tolist(), axis=0), dtype=torch.float32).to(device)\n",
    "\n",
    "pages_and_chunks = text_chunks_and_embeddings_df.to_dict(orient='records')\n",
    "\n",
    "text_chunks_and_embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4773d0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['примерно од- ный ребёнок десять это возникать определённый трудности10. проблема мочь составлять плохой ощущение личный простран- ства, ребёнок время разговор вставать слишком близко собе- седник разбрасывать свой вещь личный территория людей; неумение расшифровывать язык телодвижение пользо- ваться им; неправильный истолкование использование выраже- ний лица, примеру, неумение устанавливать зрительный контакт неспособность правильно расставить акцент отрегулировать']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(text_chunks_and_embeddings_df['sentence_text']), k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd94fdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3371, 384])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12d7d394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Delta-Game\\first_rag\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "embedding_model = SentenceTransformer(model_name_or_path=model_id, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de557346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: На чем строится доверие между людьми\n",
      "torch.Size([384])\n",
      "[INFO] Time taken to compute dot product scores: 0.0001 seconds \n",
      " len = 3371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.6723, 0.6044, 0.6013, 0.5934, 0.5917], device='cuda:0'),\n",
       "indices=tensor([1232, 2901, 3081, 3069, 2264], device='cuda:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import perf_counter as timer\n",
    "\n",
    "query = 'На чем строится доверие между людьми'\n",
    "print(f'Query: {query}')\n",
    "\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True).to(device)\n",
    "\n",
    "print(query_embedding.shape)\n",
    "\n",
    "\n",
    "cosine_scores = util.cos_sim(query_embedding, embeddings)[0]\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(f'[INFO] Time taken to compute dot product scores: {end_time - start_time:.4f} seconds \\n len = {len(embeddings)}')\n",
    "\n",
    "top_results = torch.topk(cosine_scores, k=5)\n",
    "top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b286f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from nltk.tokenize import word_tokenize  # Для токенизации\n",
    "\n",
    "# Токенизируйте чанки заранее (используйте DF из [30] для удобства; если нет, замените на pages_and_chunks_over_min_token_len)\n",
    "# tokenized_chunks = [word_tokenize(chunk.lower()) for chunk in text_chunks_and_embeddings_df['sentence_text']]  # Если DF загружен\n",
    "\n",
    "tokenized_chunks = [word_tokenize(chunk['sentence_text'].lower()) for chunk in pages_and_chunks_over_min_token_len]  # Для списка\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_chunks)\n",
    "\n",
    "# Для запроса\n",
    "tokenized_query = word_tokenize(query.lower())\n",
    "bm25_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "# Гибрид: Нормализуйте и комбинируйте (alpha=0.5 для баланса)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Переносим cosine_scores на CPU и конвертируем в numpy\n",
    "cosine_scores_cpu = cosine_scores.cpu().numpy()  # Добавьте эту строку\n",
    "\n",
    "# Теперь используем CPU-версию\n",
    "norm_cos = scaler.fit_transform(cosine_scores_cpu.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Для bm25_scores (если это list, преобразуем в numpy)\n",
    "bm25_scores_np = np.array(bm25_scores)  # На всякий случай\n",
    "norm_bm25 = scaler.fit_transform(bm25_scores_np.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "# hybrid_scores = 0.5 * norm_cos + 0.5 * norm_bm25\n",
    "hybrid_scores = 0.3 * norm_cos + 0.7 * norm_bm25\n",
    "\n",
    "\n",
    "# Продолжаем как раньше\n",
    "top_results = torch.topk(torch.tensor(hybrid_scores), k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4f3874d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Delta-Game\\first_rag\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerank Score: -4.6401 | Text: уверенность. чувство контроль владение свой телом, управление свой поведением, доверие миру; ребёнок ощущает, он, скорее всего, суметь сделать то, берет- ся, взрослый помогут. 2. любознательность. ребёнок нравиться узнавать разный но- вых вещах.\n",
      "Rerank Score: -5.3266 | Text: спо- собность держать свой порыв узда — основа сила воля характе- ра человека. аналогично основа альтруизм лежать эмпатия, умение распознавать эмоция людей. понимание нужда отчаяние человека, беспокоиться чем. мораль- ные установки, который большой весь нуждаться наш общество се- годень , — это самоконтроль сострадание.\n",
      "Rerank Score: -5.9334 | Text: это человек реальный проблемами; отчаянно хотеть разрешить свой проблемы. поверили, тм помочь найти выход. друг показал, теория, который надеялись, ложная. паника! чтоть сделать немедленно, прежде логика взять свой снова оставить надежды. необходимо быстро возвести стены, укрыться довод рассудка. иметь значения, крепость, который строится, похожий карточный домик. « скорый укромный место, скрыться логичный мыслей! вот, взять деньги. фюйть, спасти вовремя.\n",
      "Rerank Score: -6.8790 | Text: а. фрейд подчеркивает, работа это этап иметь ещё общий действительный аналитический рабо- той, т. е. ещё речь перевод сознание бессознательный процесс аналитический воздействие пациента. подгото- вительный этап иметь цель создать предварительный условия, необ- ходить начало анализа: сознание болезни, доверие решение пройти анализ [66]. 8 1963 г. а. фрейд описать линия развитие ребенка, придать теория завершить вид, однако имя автор идея (г. хут-хельмут) остаться несправедливый забытым. 9 гермин хуг-хельмут убитый свой племянник рольфом, анализ который проводить который причислять «трудным» ребёнок (на момент убийство рольф 18 лет).\n",
      "Rerank Score: -10.0667 | Text: запомнить ощуще- ния, спокойно подумать чем: именно определяете, чувствовать комфортно? физический ощущение со- стоить ваш общий чувство комфорта? чувство приносить больший осознавание ощущение – стать комфортнее, наоборот? изменяться это течение времени? присесть ми-\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "reranker = CrossEncoder('cross-encoder/mmarco-mMiniLMv2-L12-H384-v1')  # Multilingual\n",
    "\n",
    "# После top_results = torch.topk(cosine_scores, k=20)  # Берите топ-20\n",
    "top_chunks = [pages_and_chunks[idx]['sentence_text'] for idx in top_results.indices.tolist()]\n",
    "pairs = [[query, chunk] for chunk in top_chunks]\n",
    "rerank_scores = reranker.predict(pairs)\n",
    "\n",
    "# Сортировка и топ-5\n",
    "reranked = sorted(zip(rerank_scores, top_chunks), key=lambda x: x[0], reverse=True)[:5]\n",
    "for score, text in reranked:\n",
    "    print(f\"Rerank Score: {score:.4f} | Text: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de7990ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "а. фрейд подчеркивает, работа это этап иметь ещё общий действительный аналитический рабо- той, т. е. ещё речь перевод сознание бессознательный процесс аналитический воздействие пациента. подгото- вительный этап иметь цель создать предварительный условия, необ- ходить начало анализа: сознание болезни, доверие решение пройти анализ [66]. 8 1963 г. а. фрейд описать линия развитие ребенка, придать теория завершить вид, однако имя автор идея (г. хут-хельмут) остаться несправедливый забытым. 9 гермин хуг-хельмут убитый свой племянник рольфом, анализ который проводить который причислять «трудным» ребёнок (на момент убийство рольф 18 лет).\n",
      "спо- собность держать свой порыв узда — основа сила воля характе- ра человека. аналогично основа альтруизм лежать эмпатия, умение распознавать эмоция людей. понимание нужда отчаяние человека, беспокоиться чем. мораль- ные установки, который большой весь нуждаться наш общество се- годень , — это самоконтроль сострадание.\n",
      "уверенность. чувство контроль владение свой телом, управление свой поведением, доверие миру; ребёнок ощущает, он, скорее всего, суметь сделать то, берет- ся, взрослый помогут. 2. любознательность. ребёнок нравиться узнавать разный но- вых вещах.\n",
      "это человек реальный проблемами; отчаянно хотеть разрешить свой проблемы. поверили, тм помочь найти выход. друг показал, теория, который надеялись, ложная. паника! чтоть сделать немедленно, прежде логика взять свой снова оставить надежды. необходимо быстро возвести стены, укрыться довод рассудка. иметь значения, крепость, который строится, похожий карточный домик. « скорый укромный место, скрыться логичный мыслей! вот, взять деньги. фюйть, спасти вовремя.\n",
      "запомнить ощуще- ния, спокойно подумать чем: именно определяете, чувствовать комфортно? физический ощущение со- стоить ваш общий чувство комфорта? чувство приносить больший осознавание ощущение – стать комфортнее, наоборот? изменяться это течение времени? присесть ми-\n"
     ]
    }
   ],
   "source": [
    "for i in top_results.indices.tolist():\n",
    "    print(text_chunks_and_embeddings_df['sentence_text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e944f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger embeddings shape: torch.Size([3371000, 384])\n",
      "[INFO] Time taken to compute dot product scores with larger embeddings: 0.0004 seconds \n",
      " len = 3371000\n"
     ]
    }
   ],
   "source": [
    "larger_embeddings = torch.randn(1000 * embeddings.shape[0], embeddings.shape[1]).to(device)\n",
    "print(f\"Larger embeddings shape: {larger_embeddings.shape}\")\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(query_embedding, larger_embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(f'[INFO] Time taken to compute dot product scores with larger embeddings: {end_time - start_time:.4f} seconds \\n len = {len(larger_embeddings)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72c20dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text: str, width: int=80):\n",
    "    wrapped_text = textwrap.fill(text, width=width)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619cba4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3d4d6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: На чем строится доверие между людьми\n",
      "\n",
      "Results:\n",
      "Score: 0.8526 | Text: а. фрейд подчеркивает, работа это этап иметь ещё общий\n",
      "действительный аналитический рабо- той, т. е. ещё речь перевод сознание\n",
      "бессознательный процесс аналитический воздействие пациента. подгото- вительный\n",
      "этап иметь цель создать предварительный условия, необ- ходить начало анализа:\n",
      "сознание болезни, доверие решение пройти анализ [66]. 8 1963 г. а. фрейд описать\n",
      "линия развитие ребенка, придать теория завершить вид, однако имя автор идея (г.\n",
      "хут-хельмут) остаться несправедливый забытым. 9 гермин хуг-хельмут убитый свой\n",
      "племянник рольфом, анализ который проводить который причислять «трудным» ребёнок\n",
      "(на момент убийство рольф 18 лет).\n",
      "Score: 0.8096 | Text: спо- собность держать свой порыв узда — основа сила воля\n",
      "характе- ра человека. аналогично основа альтруизм лежать эмпатия, умение\n",
      "распознавать эмоция людей. понимание нужда отчаяние человека, беспокоиться чем.\n",
      "мораль- ные установки, который большой весь нуждаться наш общество се- годень ,\n",
      "— это самоконтроль сострадание.\n",
      "Score: 0.7731 | Text: уверенность. чувство контроль владение свой телом,\n",
      "управление свой поведением, доверие миру; ребёнок ощущает, он, скорее всего,\n",
      "суметь сделать то, берет- ся, взрослый помогут. 2. любознательность. ребёнок\n",
      "нравиться узнавать разный но- вых вещах.\n",
      "Score: 0.7684 | Text: это человек реальный проблемами; отчаянно хотеть разрешить\n",
      "свой проблемы. поверили, тм помочь найти выход. друг показал, теория, который\n",
      "надеялись, ложная. паника! чтоть сделать немедленно, прежде логика взять свой\n",
      "снова оставить надежды. необходимо быстро возвести стены, укрыться довод\n",
      "рассудка. иметь значения, крепость, который строится, похожий карточный домик. «\n",
      "скорый укромный место, скрыться логичный мыслей! вот, взять деньги. фюйть,\n",
      "спасти вовремя.\n",
      "Score: 0.7532 | Text: запомнить ощуще- ния, спокойно подумать чем: именно\n",
      "определяете, чувствовать комфортно? физический ощущение со- стоить ваш общий\n",
      "чувство комфорта? чувство приносить больший осознавание ощущение – стать\n",
      "комфортнее, наоборот? изменяться это течение времени? присесть ми-\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Results:\")\n",
    "\n",
    "for score, idx in zip(top_results[0], top_results[1]):\n",
    "    print_wrapped(f\"Score: {score:.4f} | Text: {pages_and_chunks[idx]['sentence_text']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2953f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
